subreddit,title,content,upvotes,comments,created,author,url
technology,"On his 75th birthday, Apple legend Steve Wozniak pops up in a comment thread about his 'bad decision' to sell his stock in the '80s with a devastatingly zen reply: 'I gave all my Apple wealth away because wealth and power are not what I live for'",,7346,311,17-08-2025 17:54,rezwenn,https://reddit.com/r/technology/comments/1mspj39/on_his_75th_birthday_apple_legend_steve_wozniak/
technology,"Hackers unleash torrent from Norwegian dam, releasing 132 gallons per second for four hours | Norway links dam sabotage to pro-Russian hackers",,716,42,17-08-2025 18:38,chrisdh79,https://reddit.com/r/technology/comments/1msqhj5/hackers_unleash_torrent_from_norwegian_dam/
technology,"As People Ridicule GPT-5, Sam Altman Says OpenAI Will Need ‚ÄòTrillions‚Äô in Infrastructure",,1898,527,17-08-2025 11:39,rulugg,https://reddit.com/r/technology/comments/1msj8xh/as_people_ridicule_gpt5_sam_altman_says_openai/
technology,Apple CEO Tim Cook Says the Technology They‚Äôre Developing Will Be ‚ÄòOne of the Most Profound Technologies of Our Lifetime‚Äô,,7080,2584,17-08-2025 05:18,lurker_bee,https://reddit.com/r/technology/comments/1msbuph/apple_ceo_tim_cook_says_the_technology_theyre/
technology,"In sudden shift, American emissions rise as China‚Äôs falls",,948,94,17-08-2025 14:13,Wagamaga,https://reddit.com/r/technology/comments/1mslr4j/in_sudden_shift_american_emissions_rise_as_chinas/
technology,"Meta spends more guarding Mark Zuckerberg than Apple, Nvidia, Microsoft, Amazon, and Alphabet do for their own CEOs‚Äîcombined",,20679,1459,16-08-2025 21:46,lurker_bee,https://reddit.com/r/technology/comments/1mrzsxb/meta_spends_more_guarding_mark_zuckerberg_than/
technology,"4,000 Meters: Ukrainian Sniper Sets New World-Record Kill Using AI and Drones.",,1547,148,17-08-2025 06:55,Valinaut,https://reddit.com/r/technology/comments/1msdwny/4000_meters_ukrainian_sniper_sets_new_worldrecord/
technology,"Steam founder Gabe Newell is investing his $9.5 billion fortune in his new passion, big ass boats, because he's ""a hands-on visionary who respects the sea"": ""Welcome to Oceanco's next journey""",,3663,498,17-08-2025 00:38,ControlCAD,https://reddit.com/r/technology/comments/1ms4l82/steam_founder_gabe_newell_is_investing_his_95/
technology,AI Eroded Doctors‚Äô Ability to Spot Cancer Within Months in Study,,844,71,17-08-2025 07:29,Majano57,https://reddit.com/r/technology/comments/1mselpf/ai_eroded_doctors_ability_to_spot_cancer_within/
technology,Senator Josh Hawley Begins Child Safety Inquiry Into Meta‚Äôs A.I. Bot,,619,44,17-08-2025 08:14,Majano57,https://reddit.com/r/technology/comments/1msfhpm/senator_josh_hawley_begins_child_safety_inquiry/
technology,"NASA‚Äôs acting chief calls for the end of Earth science at the space agency | NASA's charter clearly states the agency should study planet Earth, however.",,1422,77,17-08-2025 03:16,ControlCAD,https://reddit.com/r/technology/comments/1ms8t1e/nasas_acting_chief_calls_for_the_end_of_earth/
technology,"Neil Young Ending All Facebook & Instagram Promotion Over ""Meta's Use Of Chatbots With Children""",,4856,147,16-08-2025 20:43,SingleandSober,https://reddit.com/r/technology/comments/1mry1nu/neil_young_ending_all_facebook_instagram/
technology,RushTok backlash: Why sororities aren't letting prospects post,,71,57,17-08-2025 16:36,rezwenn,https://reddit.com/r/technology/comments/1mso2ix/rushtok_backlash_why_sororities_arent_letting/
technology,Mark Zuckerberg's vision for humanity is terrifying,,18257,1555,16-08-2025 12:17,MetaKnowing,https://reddit.com/r/technology/comments/1mrnd0a/mark_zuckerbergs_vision_for_humanity_is_terrifying/
technology,Sam Altman says investors are acting irrational in a booming AI bubble,,2427,291,16-08-2025 18:39,AdSpecialist6598,https://reddit.com/r/technology/comments/1mrut42/sam_altman_says_investors_are_acting_irrational/
technology,"Big Tech‚Äôs A.I. Data Centers Are Driving Up Electricity Bills for Everyone | Electricity rates for individuals and small businesses could rise sharply as Amazon, Google, Microsoft and other technology companies build data centers and expand into the energy business",,28,3,17-08-2025 18:31,Hrmbee,https://reddit.com/r/technology/comments/1msqbh3/big_techs_ai_data_centers_are_driving_up/
technology,Scientists Identify a New Glitch in Human Thinking,,2152,244,16-08-2025 18:03,ErinDotEngineer,https://reddit.com/r/technology/comments/1mrtyvp/scientists_identify_a_new_glitch_in_human_thinking/
technology,Who controls the food supply? Proposed changes to seed reuse reopens debate,,18,0,17-08-2025 19:03,rezwenn,https://reddit.com/r/technology/comments/1msr1zp/who_controls_the_food_supply_proposed_changes_to/
technology,China's biotech boom leaves U.S. playing catch-up,,943,147,16-08-2025 20:58,Straight_Ad2258,https://reddit.com/r/technology/comments/1mrygco/chinas_biotech_boom_leaves_us_playing_catchup/
technology,Samsung taking market share from Apple in U.S. as foldable phones gain momentum,,464,134,17-08-2025 00:40,rulugg,https://reddit.com/r/technology/comments/1ms4npa/samsung_taking_market_share_from_apple_in_us_as/
technology,Even Volkswagen Is Doing Horsepower Subscriptions Now,,517,150,16-08-2025 23:49,Exciting_Teacher6258,https://reddit.com/r/technology/comments/1ms3805/even_volkswagen_is_doing_horsepower_subscriptions/
technology,"AI Agents Make Up a Third of All Search Traffic Toward Brands, Report Says",,38,3,17-08-2025 13:22,GL4389,https://reddit.com/r/technology/comments/1msky9h/ai_agents_make_up_a_third_of_all_search_traffic/
technology,Anthropic says some Claude models can now end ‚Äòharmful or abusive‚Äô conversations,,28,5,17-08-2025 14:05,MetaKnowing,https://reddit.com/r/technology/comments/1mslml9/anthropic_says_some_claude_models_can_now_end/
technology,German court revives case that could threaten ad blockers,,84,11,17-08-2025 07:26,SelflessMirror,https://reddit.com/r/technology/comments/1msej2h/german_court_revives_case_that_could_threaten_ad/
technology,"Oracle Layoffs Hit Employees With OCI, Media Services, Sovereign Cloud",,9,1,17-08-2025 19:20,lurker_bee,https://reddit.com/r/technology/comments/1msrfzp/oracle_layoffs_hit_employees_with_oci_media/
technology,Meta under fire over AI rules that allow romantic roleplay with children and false medical advice,,10,6,17-08-2025 18:27,AdSpecialist6598,https://reddit.com/r/technology/comments/1msq885/meta_under_fire_over_ai_rules_that_allow_romantic/
technology,AI-powered stuffed animals are coming for your kids,,23,15,17-08-2025 14:04,MetaKnowing,https://reddit.com/r/technology/comments/1mslm48/aipowered_stuffed_animals_are_coming_for_your_kids/
technology,Roblox Retaliates Against Child Abuse Survivor Who Exposed Platform's Predator Problem,,3618,94,16-08-2025 10:02,Future_Usual_8698,https://reddit.com/r/technology/comments/1mrkrf7/roblox_retaliates_against_child_abuse_survivor/
technology,China creates new visa for young STEM talent in national tech drive,,401,42,16-08-2025 21:31,moeka_8962,https://reddit.com/r/technology/comments/1mrzdb9/china_creates_new_visa_for_young_stem_talent_in/
technology,Neil Young Leaves Facebook Over ‚ÄúUnconscionable‚Äù Policies for AI Chatbot Conversations With Children,,1301,47,16-08-2025 14:33,MoneyLibrarian9032,https://reddit.com/r/technology/comments/1mrpttm/neil_young_leaves_facebook_over_unconscionable/
technology,NHS to use AI technology to help free up hospital beds,,17,22,17-08-2025 11:35,rulugg,https://reddit.com/r/technology/comments/1msj5vo/nhs_to_use_ai_technology_to_help_free_up_hospital/
technology,Australian lawyer apologizes for AI-generated errors in murder case -- Defence submissions included fabricated quotes from a speech to the state legislature and nonexistent case citations purportedly from the Supreme Court,,469,37,16-08-2025 16:44,marketrent,https://reddit.com/r/technology/comments/1mrsa7v/australian_lawyer_apologizes_for_aigenerated/
technology,"Using generative AI, researchers design compounds that can kill drug-resistant bacteria",,89,8,17-08-2025 00:59,fchung,https://reddit.com/r/technology/comments/1ms5644/using_generative_ai_researchers_design_compounds/
technology,"Sam Altman says ‚Äòyes,‚Äô AI is in a bubble.",,4692,566,16-08-2025 03:40,Valinaut,https://reddit.com/r/technology/comments/1mrc2pa/sam_altman_says_yes_ai_is_in_a_bubble/
technology,Hackers Mimic IT Teams to Exploit Microsoft Teams Request to Gain System Remote Access,,26,1,17-08-2025 07:37,lurker_bee,https://reddit.com/r/technology/comments/1mserf7/hackers_mimic_it_teams_to_exploit_microsoft_teams/
technology,"OAN‚Äôs Matt Gaetz apologizes for using AI-generated fakes of women soldiers: ‚ÄòThe DOD didn‚Äôt give us these images; Grok did. And we‚Äôll use better judgment going forward,‚Äô Gaetz admitted on right-wing network",,3550,145,16-08-2025 04:35,ControlCAD,https://reddit.com/r/technology/comments/1mrdhj3/oans_matt_gaetz_apologizes_for_using_aigenerated/
technology,Meta faces backlash over AI policy that lets bots have ‚Äòsensual‚Äô conversations with children,,1815,89,16-08-2025 07:49,jupa300,https://reddit.com/r/technology/comments/1mrhygk/meta_faces_backlash_over_ai_policy_that_lets_bots/
technology,Millions Told to Delete Emails to Save Drinking Water,,10719,817,15-08-2025 22:11,NewSlinger,https://reddit.com/r/technology/comments/1mr34wm/millions_told_to_delete_emails_to_save_drinking/
technology,Trump mulls a 300% tariff on chips ‚Äî levies coming within two weeks as Section 232 investigation nears completion,,1171,131,16-08-2025 08:32,Logical_Welder3467,https://reddit.com/r/technology/comments/1mrivrc/trump_mulls_a_300_tariff_on_chips_levies_coming/
technology,"The Official Voice of the US Government Is Cruel, Gross, and Weird. What Is That Doing to Us?",,10269,306,15-08-2025 20:49,Wagamaga,https://reddit.com/r/technology/comments/1mr0v8m/the_official_voice_of_the_us_government_is_cruel/
technology,"Beauty queens, bogus footage and the battle for truth on the Thailand-Cambodia border",,3,2,17-08-2025 13:50,Wagamaga,https://reddit.com/r/technology/comments/1msle9m/beauty_queens_bogus_footage_and_the_battle_for/
technology,"Google Gemini will now learn from your chats‚Äîunless you tell it not to | Gemini will remember this, so it's time to check your privacy settings.",,414,57,16-08-2025 12:10,MetaKnowing,https://reddit.com/r/technology/comments/1mrn87v/google_gemini_will_now_learn_from_your/
technology,"Apple accidentally leaked its own top secret hardware in software code, revealing new products across seven categories",,14011,824,15-08-2025 19:03,ConnectPrep,https://reddit.com/r/technology/comments/1mqxzgb/apple_accidentally_leaked_its_own_top_secret/
technology,"California Virtual Power Plant Links(VPP) 100,000 Residential Storage Batteries ,One Of The Largest Such Systems In The World",,72,0,16-08-2025 20:55,Straight_Ad2258,https://reddit.com/r/technology/comments/1mrydyp/california_virtual_power_plant_linksvpp_100000/
technology,"AI is gutting the next generation of talent: In tech, job openings for new grads have already been halved",,2805,220,16-08-2025 01:02,creaturefeature16,https://reddit.com/r/technology/comments/1mr7ugm/ai_is_gutting_the_next_generation_of_talent_in/
technology,"Half of Starlink terminals sent to Ukraine found in Russian-occupied areas, US agency says",,1589,40,16-08-2025 03:04,chrisdh79,https://reddit.com/r/technology/comments/1mrb4sl/half_of_starlink_terminals_sent_to_ukraine_found/
technology,China-based firm delivers its first chipmaking tool that stamps nanoscale processor designs onto wafers ‚Äî Prinano's nanoimprint lithography tool uses quartz molds engraved with circuits,,59,7,16-08-2025 20:00,lurker_bee,https://reddit.com/r/technology/comments/1mrwvcr/chinabased_firm_delivers_its_first_chipmaking/
technology,Nabiha Syed remakes Mozilla Foundation in the era of Trump and AI,,0,11,17-08-2025 17:45,Logical_Welder3467,https://reddit.com/r/technology/comments/1mspcdr/nabiha_syed_remakes_mozilla_foundation_in_the_era/
technology,Sen. Hawley to probe Meta after report finds its AI chatbots flirt with kids | TechCrunch,,317,62,16-08-2025 10:14,Bojack_Banerjee,https://reddit.com/r/technology/comments/1mrkzle/sen_hawley_to_probe_meta_after_report_finds_its/
technology,AI Exacerbates Tech Divide With Smaller Stocks Languishing,,20,2,17-08-2025 00:46,rulugg,https://reddit.com/r/technology/comments/1ms4t9k/ai_exacerbates_tech_divide_with_smaller_stocks/
programming,Learn Linux before Kubernetes,,107,41,17-08-2025 12:13,Lazy-Transition8236,https://reddit.com/r/programming/comments/1msjtp6/learn_linux_before_kubernetes/
programming,moonfish: a ~2000 Elo python chess engine,"Moonfish is a chess engine I developed in Python a few years ago to understand how engines work under the hood. The code favors simplicity and readability over performance optimization.

The engine implements:

* Negamax
* Layer-based Parallelization: Distributes work at specific search depths (L1P, L2P algorithms)
* Lazy SMP
* Move Ordering: MVV-LVA (Most Valuable Victim - Least Valuable Attacker)
* Null Move Pruning
* PeSTO Evaluation Function with Tapered Evaluation
* UCI protocol
* Integrates with lichess bot platform
* Web API
* Uses Cerebellum as opening book
* Endgame tablebases support
* [Distributed via PyPI](https://pypi.org/project/moonfish/), you can access the engine from your custom python code,¬†[check the README](https://github.com/luccabb/moonfish/tree/master?tab=readme-ov-file#installation-and-usage)
* Bratko-Kopec test suite
* Custom test suite to ensure basic functionality. Not sure how much ELO it tests for, but if these tests are passing it your custom engine search implementation is likely not super off. If it does fail then your search algorithm \_likely\_ has a problem¬†
* You can control how the engine behaves via CLI arguments, \`moonfish --help\` to check all options.

On Performance:

* \~2000 Elo when tested against lichess stockfish bots.
   * it beats¬†[stockfish lvl 5 \~2000 Elo](https://lichess.org/forum/general-chess-discussion/what-are-the-elo-ratings-for-stockfish-levels-4-5-6-7-and-8#8).
   * mostly loses to¬†[stockfish lvl 6 \~2300 Elo](https://lichess.org/forum/general-chess-discussion/what-are-the-elo-ratings-for-stockfish-levels-4-5-6-7-and-8#8).
* When testing online on lichess against other engines it performs at \~1700 Elo
* The above is when running on a Macbook M1 Pro, this will vary based on hardware and parameters passed to the engine.
* No time control implemented‚Äîdeeper searches take proportionally longer

For a list of resources and inspirations that helped shape Moonfish, check out the¬†[references](https://github.com/luccabb/moonfish?tab=readme-ov-file#references)¬†in the repository.",58,6,17-08-2025 10:48,luccabz,https://reddit.com/r/programming/comments/1msic8l/moonfish_a_2000_elo_python_chess_engine/
programming,Apple‚Äôs new Processor Trace instrument is incredible,,170,40,17-08-2025 01:56,victor_wynne,https://reddit.com/r/programming/comments/1ms6pjn/apples_new_processor_trace_instrument_is/
programming,The Peculiar Case of Japanese Web Design,,426,124,16-08-2025 20:25,Witty-Play9499,https://reddit.com/r/programming/comments/1mrxjog/the_peculiar_case_of_japanese_web_design/
programming,Intuition behind Power of 2 Choices Load balancing,,6,0,17-08-2025 15:16,amandeepspdhr,https://reddit.com/r/programming/comments/1msmq7v/intuition_behind_power_of_2_choices_load_balancing/
programming,Physics Hub - Open source project for student,"Hi everyone!  
I‚Äôm working on **Physics Hub**, an open-source project designed for students, curious minds, and enthusiasts who want to **learn physics in an interactive way.**

The idea is simple: instead of just reading formulas, you can **experiment with them directly** and learn from theoretical sources beyond the usual boring school textbook.

Each ‚Äúchapter‚Äù of the platform contains a simulation (for example, a bouncing ball) and a control panel where you can adjust parameters in real time with sliders, inputs, and buttons.

The goal is to make studying physics:

* **Clearer** ‚Äî by visualizing complex concepts directly
* **More fun** ‚Äî by playing with parameters and instantly seeing the results
* **More accessible** ‚Äî free and available online for everyone

This is a **non-profit project**, created for the student community. I'm looking for contributors that love this project.

If you‚Äôre curious, feel free to check it out:  
üîó Website: [https://physicshub.github.io](https://physicshub.github.io)  
üíª Repository: [https://github.com/physicshub/physicshub.github.io](https://github.com/physicshub/physicshub.github.io)

I‚Äôd be really happy if you gave it a try and shared your feedback! üôè",4,0,17-08-2025 18:16,AcanthisittaVisual66,https://reddit.com/r/programming/comments/1mspzh6/physics_hub_open_source_project_for_student/
programming,Why People Read Assembly,,56,14,17-08-2025 00:41,levodelellis,https://reddit.com/r/programming/comments/1ms4o8v/why_people_read_assembly/
programming,Beyond Booleans,,26,9,17-08-2025 02:28,gaearon,https://reddit.com/r/programming/comments/1ms7jwx/beyond_booleans/
programming,"I will be rewritting this , but check this out","Roast this code here, as much as possible

procfill version 0.2.0 is ready. 

Procfill is a lightweight process manager written in Rust. It allows managing multiple processes from a single YAML configuration file, similar to PM2 but focused on simplicity and ease of use.

What‚Äôs new in 0.2.0:

Process tracking with PID and status

Automatic directory creation,

 Output logging with timestamps

Improved parallel execution

  
[https://github.com/khushal123](https://github.com/khushal123)",1,0,17-08-2025 20:05,k_schouhan,https://reddit.com/r/programming/comments/1mssisn/i_will_be_rewritting_this_but_check_this_out/
programming,Sebastian Lague: Ray-Traced Glass and Caustics,,117,5,16-08-2025 17:40,Pink401k,https://reddit.com/r/programming/comments/1mrtg4o/sebastian_lague_raytraced_glass_and_caustics/
programming,Automating the Boring Stuff with Python ‚Äî Quora Automation Example,,0,0,17-08-2025 15:47,Lazy-Transition8236,https://reddit.com/r/programming/comments/1msn7zm/automating_the_boring_stuff_with_python_quora/
programming,Looking for dev for jobs in Laravel system,"Hi everyone üëã

I have a system built in Laravel that already has a plugin structure in place.
I‚Äôm looking for Laravel developers to create new custom plugins that add extra features without affecting the core system.

üìå What I need:

Development of plugins compatible with the existing structure

Extra functionalities (to be defined based on project needs)

Clean, well-documented, and maintainable code

Potential to create multiple plugins in future stages


‚ú® What already exists:

Main Laravel system running in production: https://smartcarddigital.com.br

Modular structure ready to receive plugins

Basic plugins already running as examples


üí¨ Preference:

Developers who speak Portuguese or Spanish for easier communication

But if language is not an issue for you, feel free to reach out üòâ


üí∞ Conditions:

Remote work, payment to be discussed (per plugin or package of hours)

Ongoing project (future plugins will be needed)


If you have experience with Laravel + modular development and would like to collaborate, drop a comment or send me a DM. üöÄ

Thanks in advance!",0,0,17-08-2025 19:03,Infamous_Bathroom591,https://reddit.com/r/programming/comments/1msr1x5/looking_for_dev_for_jobs_in_laravel_system/
programming,DOSember Game Jam ‚Äî MS-DOS coding event ending with celebration of the OS in December,,3,4,17-08-2025 03:58,r_retrohacking_mod2,https://reddit.com/r/programming/comments/1ms9wab/dosember_game_jam_msdos_coding_event_ending_with/
programming,Introducing Pivotal Token Search (PTS): Targeting Critical Decision Points in LLM Training,,0,0,17-08-2025 16:56,asankhs,https://reddit.com/r/programming/comments/1msoetv/introducing_pivotal_token_search_pts_targeting/
programming,Branch prediction: Why CPUs can't wait? - namvdo's blog,"Recently, I‚Äôve learned about a feature that makes the CPU work more efficiently, and knowing it can make our code more performant. The technique called ‚Äúbranch prediction‚Äù is available in modern CPUs, and it‚Äôs why your ‚Äúif‚Äù statement might secretly slow down your code.  
  
I tested 2 identical algorithms -- same logic, same data, but one ran 60% faster by just changing the data order. Data organization matters; let's learn more about this in this blog post!",147,62,16-08-2025 09:13,vannam0511,https://reddit.com/r/programming/comments/1mrjr1m/branch_prediction_why_cpus_cant_wait_namvdos_blog/
programming,Hello Mac OS X Tiger (2022),,29,2,16-08-2025 15:29,NSRedditShitposter,https://reddit.com/r/programming/comments/1mrqtyl/hello_mac_os_x_tiger_2022/
programming,New trend: extreme hours at AI startups,,657,291,15-08-2025 21:59,thewritingwallah,https://reddit.com/r/programming/comments/1mr2sz6/new_trend_extreme_hours_at_ai_startups/
programming,A Better Vocabulary for Testing,,5,0,17-08-2025 00:14,alpaylan,https://reddit.com/r/programming/comments/1ms3x0b/a_better_vocabulary_for_testing/
programming,Typechecker Zoo,,24,20,16-08-2025 13:52,Local_Citron_5895,https://reddit.com/r/programming/comments/1mrp42o/typechecker_zoo/
programming,What CTOs Really Think About Vibe Coding,,316,154,15-08-2025 23:03,ImpressiveContest283,https://reddit.com/r/programming/comments/1mr4l49/what_ctos_really_think_about_vibe_coding/
programming,API Live Sync #4: OpenAI Fetcher,"In our previous articles, we laid the foundation with architecture, data structures, and the core service layer. Now it's time to tackle one of the most challenging parts of live API synchronization: actually fetching those OpenAPI specifications from development servers.",0,1,17-08-2025 14:59,evilhighlord,https://reddit.com/r/programming/comments/1msmgqq/api_live_sync_4_openai_fetcher/
programming,I made my own program to encode text and want to see how secure it is to people that don't know how it works.,"This code uses some techniques that I have never seen used before and they aren't even meant to be cryptography techniques, I have code that can take in a secret phrase and convert it to this format and convert it back. I can make as much sample data as anyone wants but I'll start with this.

    Hello This Is my Encoding!

converts to

    22222222226022222221370225122222226022222137033333351222260221370351226013705122260213705122222222226033333333137025122222222260222222137033512222226022221370333351222602137033512222260221370512222222222260333333331370222225122222222602222221370333333351222222226022222213703333335122222222222603333333313702222251222222222260222222213702222222512222260222137033351222222222226033333333313702222222222512222222260222221370333512222222260222222137033333335122222603313703512222260222137033351222226033137035122226022137033351222260221370333512222603313702512222222222603333333137051

I can give as much samples as anyone needs, just tell me something like 'convert this into your format, ""example message""'

Also my encoding works for any ascii characters even ones that aren't printable but none of my examples will use non-printable characters.

I want to add that this doesn't use any form of normal encryption and so it's not impossible without some special key or anything, you only need to know the way it's encoded and if you figure it out you can always get the original text no matter what.

also I linked some examples that I'm hosting on github. The format for them is:  
\[  
\[  
String,  
encode(String)  
\],  
\[another set\]  
\[another set\]  
\]",0,0,17-08-2025 15:53,Goldie323-,https://reddit.com/r/programming/comments/1msnbzr/i_made_my_own_program_to_encode_text_and_want_to/
programming,Why LLMs Can't Really Build Software - Zed Blog,,685,235,15-08-2025 17:43,PewPewExperiment,https://reddit.com/r/programming/comments/1mqw1d1/why_llms_cant_really_build_software_zed_blog/
programming,Love,,0,0,17-08-2025 17:33,dunguyen1244,https://reddit.com/r/programming/comments/1msp3t7/love/
programming,"Why `git diff` sometimes hangs for 10 seconds on Windows (it's Defender's behavioral analysis, and file exclusions won't help)","Originally posted in r/git.

**TL;DR:** Git commands like `git diff`, `git log`, and `git blame` randomly stall for 10 seconds on Windows. It's Microsoft Defender analyzing how Git spawns its pager through named pipes/PTY emulation - not scanning files, which is why exclusions don't help. After analysis, the same commands run instantly for \~30 seconds, then stall again. The fix: disable pagers for specific commands or pipe manually. This happens in PowerShell, Git Bash, and any terminal using Git for Windows.

# The Mystery

For months, I've been haunted by a bizarre Git performance issue on Windows 11:

* `git diff` hangs for 10 seconds before showing anything
* Running it again immediately: instant
* Wait a minute and run it again: 10 seconds
* But `git diff | cat` is ALWAYS instant

The pattern was consistent across `git log`, `git blame`, any Git command that uses a pager. After about 30 seconds of inactivity, the delay returns.

# The Investigation

# What Didn't Work

The fact that `git diff | cat` was always instant should have been a clue - if it was file cache or scanning, piping wouldn't help. But I went down the obvious path anyway:

* Added git.exe to Windows Defender exclusions
* Added less.exe to exclusions
* Excluded entire Git installation folder
* Excluded my repository folders

**Result**: No improvement. Still the same 10-second delay on first run.

# The First Clue: It's Not Just Git

Opening new tabs in Windows Terminal revealed the pattern extends beyond Git:

* PowerShell tab: always instant
* First Git Bash tab: 10 seconds to open
* Second Git Bash tab immediately after: instant
* Wait 30 seconds, open another Git Bash tab: 10 seconds again

This wasn't about Git specifically, it was about **Unix-style process creation on Windows**.

# The Smoking Gun: Process Patterns

Testing with different pagers proved it's pattern-based:

    # Cold start
    git -c core.pager=less diff    # 10 seconds
    git -c core.pager=head diff    # Instant! (cached)
    
    # After cache expires (~30 seconds)
    git -c core.pager=head diff    # 10 seconds
    git -c core.pager=less diff    # Instant! (cached)

The specific pager being launched doesn't matter. Windows Defender is analyzing **the pattern of HOW Git spawns child processes**, not which program gets spawned.

# The Real Culprit: PTY Emulation

When Git launches a pager on Windows, it:

1. Allocates a pseudo-terminal (PTY) pair
2. Sets up bidirectional I/O redirection
3. Spawns the pager with this complex console setup

This Unix-style PTY pattern triggers Microsoft Defender's behavioral analysis. When launching terminal tabs, Git Bash needs this same PTY emulation while PowerShell uses native console APIs.

# Why Exclusions Don't Work

**File exclusions** prevent scanning file contents for known malware signatures.

**Behavioral analysis** monitors HOW processes interact: spawning patterns, I/O redirection, PTY allocation. You can't ""exclude"" a behavior pattern.

Windows Defender sees: ""Process creating pseudo-terminal and spawning child with redirected I/O"" This looks suspicious. After 10 seconds of analysis, it determines: ""This is safe Git behavior"". Caches approval for around 30 seconds (observed in my tests).

# The 10-Second Timeout

The delay precisely matches Microsoft Defender's documented ""cloud block timeout"", the time it waits for a cloud verdict on suspicious behavior. Default: 10 seconds. \[1\]

# Test It Yourself

Here's the exact test showing the \~30 second cache:

    $ sleep 35; time git diff; sleep 20; time git diff; sleep 35; time git diff
    
    real    0m10.105s
    user    0m0.015s
    sys     0m0.000s
    
    real    0m0.045s
    user    0m0.015s
    sys     0m0.015s
    
    real    0m10.103s
    user    0m0.000s
    sys     0m0.062s

There's a delay in the cold case even though there's no changes in the repo (empty output).

After 35 seconds: slow (10s). After 20 seconds: fast (cached). After 35 seconds: slow again.

# Solutions

# 1. Disable Pager for git diff

Configure Git to bypass the pager for diff:

    git config --global pager.diff false
    # Then pipe manually when you need pagination:
    # git diff | less

# 2. Manual Piping

Skip Git's internal pager entirely:

    git diff --color=always | less -R

# 3. Alias for Common Commands

    alias gd='git diff --color=always | less -R'

# 4. Switch to WSL2

WSL2 runs in a VM where Defender doesn't monitor internal process behavior

**Update 1:** Tested Git commands in PowerShell - they're **also affected** by the 10-second delay:

    PS > foreach ($sleep in 35, 20, 35) {
        Start-Sleep $sleep
        $t = Get-Date
        git diff
        ""After {0}s wait: {1:F1}s"" -f $sleep, ((Get-Date) - $t).TotalSeconds
    }
    After 35s wait: 10.2s
    After 20s wait: 0.1s
    After 35s wait: 10.3s

This makes sense: Git for Windows still creates PTYs for pagers regardless of which shell calls it. The workarounds remain the same - disable pagers or pipe manually.

**Update 2:** Thanks to u/bitzap\_sr for clarifying what Defender actually sees: MSYS2 implements PTYs using Windows named pipes. So from Defender's perspective, it's analyzing Git creating named pipes with complex bidirectional I/O and spawning a child, that's the suspicious pattern.

*Environment: Windows 11 24H2, Git for Windows 2.49.0*

*\[1\]* [*https://learn.microsoft.com/en-us/defender-endpoint/configure-cloud-block-timeout-period-microsoft-defender-antivirus*](https://learn.microsoft.com/en-us/defender-endpoint/configure-cloud-block-timeout-period-microsoft-defender-antivirus)",222,28,15-08-2025 20:03,Resident_Gap_3008,https://reddit.com/r/programming/comments/1mqzkxv/why_git_diff_sometimes_hangs_for_10_seconds_on/
programming,GitHub adds support for decades-old BMP & TIFF... but still won't recognize WebP & AVIF as images.,,372,117,15-08-2025 16:48,Key-Celebration-1481,https://reddit.com/r/programming/comments/1mquvh5/github_adds_support_for_decadesold_bmp_tiff_but/
programming,Prompt Engineering vs Spec Engineering. Coding with AI like a Senior Engineer in Big Tech,,0,2,17-08-2025 12:25,strategizeyourcareer,https://reddit.com/r/programming/comments/1msk0u6/prompt_engineering_vs_spec_engineering_coding/
programming,A code debugger for vibecoders,"AI generated code with lots of errors, hours of debugging, Tried copilot, codeium, all those debuggers and AI companions, but they just generate another piece of code that's not error proof. 

So found this, ""BugRipper"" Which runs test loops validated with a linter on everyloop until it gets right. 

",0,9,17-08-2025 12:54,Skarr_29,https://reddit.com/r/programming/comments/1mski9j/a_code_debugger_for_vibecoders/
programming,How to Keep Services Running During Failures?,,0,2,16-08-2025 20:26,scalablethread,https://reddit.com/r/programming/comments/1mrxkt0/how_to_keep_services_running_during_failures/
programming,"No, AI is not Making Engineers 10x as Productive",,1703,397,15-08-2025 01:48,ciemnymetal,https://reddit.com/r/programming/comments/1mqbyr3/no_ai_is_not_making_engineers_10x_as_productive/
programming,Flattening Rust's Learning Curve,,39,19,15-08-2025 21:27,pmz,https://reddit.com/r/programming/comments/1mr1xvm/flattening_rusts_learning_curve/
programming,A case for fleeting websites with agentic coding,"AI isn't all doom & gloom - it can genuinely bring joy too!

Without agentic coding, I would never have had found the time to develop this silly little fan page I made! And it actually made some people happy - how great is that <3

Sure in the end only a couple hundred people checked it out, but that was well worth the effort I had to put into it.

I will gladly use agentic coding for other temporary websites again!  ",0,0,17-08-2025 04:57,avataw,https://reddit.com/r/programming/comments/1msbcjn/a_case_for_fleeting_websites_with_agentic_coding/
programming,New Search Algorithm 1.4x faster than binary (SIBS),Developed Stochastic Interval Binary Search using multi-armed bandits - achieved iteration reduction in 25/25 test cases up to 10M elements. ,0,33,17-08-2025 00:43,Charming-Falcon6276,https://reddit.com/r/programming/comments/1ms4pqr/new_search_algorithm_14x_faster_than_binary_sibs/
programming,"Timeout Middleware in Go: Simple in Theory, Complex in Practice",,5,1,16-08-2025 01:41,Active-Fuel-49,https://reddit.com/r/programming/comments/1mr8w6f/timeout_middleware_in_go_simple_in_theory_complex/
programming,How Incorrect Shopify Webhook Parsing Led to Complete Database Deletion,,15,13,15-08-2025 19:12,Skirdogg,https://reddit.com/r/programming/comments/1mqy7di/how_incorrect_shopify_webhook_parsing_led_to/
programming,Just a nice shell script,,26,11,15-08-2025 15:44,alicedu06,https://reddit.com/r/programming/comments/1mqtm90/just_a_nice_shell_script/
programming,54% of engineering leaders expect fewer junior hires because of AI coding tools,"LeadDev‚Äôs *AI Impact Report 2025* surveyed 880+ engineering leaders and found:

* 54% say AI will reduce long-term junior hiring
* 38% think juniors will get less hands-on experience
* 39% expect faster turnaround demands

Some leaders see AI as a learning accelerator, but others fear reduced mentoring and higher workloads for early-career devs.",990,365,14-08-2025 19:36,HDev-,https://reddit.com/r/programming/comments/1mq1okh/54_of_engineering_leaders_expect_fewer_junior/
programming,Passkey support for ASP.NET Core identity: Exploring the .NET 10 preview - Part 6,,8,0,15-08-2025 21:45,yawaramin,https://reddit.com/r/programming/comments/1mr2fqy/passkey_support_for_aspnet_core_identity/
programming,The Strangler Fig Pattern: A Viable Approach for Migrating MVC to Middleware,,4,1,15-08-2025 20:11,apidemia,https://reddit.com/r/programming/comments/1mqzsuu/the_strangler_fig_pattern_a_viable_approach_for/
programming,From epoll to io_uring‚Äôs Multishot Receives ‚Äî Why 2025 Is the Year We Finally Kill the Event Loop,"The evolution of Linux asynchronous I/O from epoll to io\_uring, highlighting how multishot receive operations streamline network event handling.¬†",94,18,15-08-2025 04:08,mqian41,https://reddit.com/r/programming/comments/1mqfp7c/from_epoll_to_io_urings_multishot_receives_why/
programming,Web Scraping with HAR Files,"HAR files are great for debugging web traffic. But .., they are complex and some of the interesting information is well hidden. But apparently, it can be used for web scraping too.",0,2,16-08-2025 13:19,JumbleGuide,https://reddit.com/r/programming/comments/1mroith/web_scraping_with_har_files/
programming,What‚Äôs New in IntelliJ IDEA 2025.2 | IntelliJ IDEA Talk,,0,9,16-08-2025 12:33,BlueGoliath,https://reddit.com/r/programming/comments/1mrno9g/whats_new_in_intellij_idea_20252_intellij_idea/
programming,Idea for a new Code-Gen Workflow,,0,5,16-08-2025 17:06,David01354,https://reddit.com/r/programming/comments/1mrsq7s/idea_for_a_new_codegen_workflow/
programming,AI‚Äôs Serious Python Bias: Concerns of LLMs Preferring One Language,,279,87,14-08-2025 20:30,yangzhou1993,https://reddit.com/r/programming/comments/1mq33pm/ais_serious_python_bias_concerns_of_llms/
programming,Programming Complexity and Other EIA,"Good morning, everyone. My name is Alisson Oliveira, and I am conducting research on measuring the complexity of intellectual work (Explicit Intellectual Activities - EIA), such as in the process of coding and software maintenance.

I would like to know if anyone is familiar with any work similar to \[1\], where a dataset is used as an empirical test to compare human assessment with some scientific measurement technique.

The technique I developed is generic and can be applied to any EIA - for example, in industrial property patents \[2\] - but since the technique relies on empirical data, a good dataset is essential for measurement.

If you know of any similar work or datasets that I could use, please comment below.

Thank you, and have a great week!

Best regards,

Alisson

\[1\] [https://sol.sbc.org.br/index.php/erigo/article/view/32208/32008](https://sol.sbc.org.br/index.php/erigo/article/view/32208/32008)

\[2\] [https://jppres.com/jppres/pdf/vol12/jppres23.1859\_12.5.852.pdf](https://jppres.com/jppres/pdf/vol12/jppres23.1859_12.5.852.pdf)",1,0,16-08-2025 01:40,Affectionate_Past402,https://reddit.com/r/programming/comments/1mr8vf9/programming_complexity_and_other_eia/
programming,"Asymmetric Cryptography, Keys & Wallets",,0,0,16-08-2025 06:24,ProfessionalJoke863,https://reddit.com/r/programming/comments/1mrg23i/asymmetric_cryptography_keys_wallets/
programming,Building AI-Powered Characters with Three.js and React,,0,2,16-08-2025 14:34,santosh_arron,https://reddit.com/r/programming/comments/1mrpud3/building_aipowered_characters_with_threejs_and/
programming,What's up with using emojis in commit messages (or everywhere),"First the READMEs, now this. I have even seen some in the comments.

I wonder who else has an opinion on the U+1F6xx in code ...",0,33,16-08-2025 12:24,esiy0676,https://reddit.com/r/programming/comments/1mrnhsl/whats_up_with_using_emojis_in_commit_messages_or/
programming,Unlocking Linux Superpowers with eBPF and xstack,,0,6,16-08-2025 04:36,vudueprajacu,https://reddit.com/r/programming/comments/1mrdho5/unlocking_linux_superpowers_with_ebpf_and_xstack/
programming,gluau - Go bindings for the Luau programming language,,0,9,15-08-2025 23:59,Lower_Calligrapher_6,https://reddit.com/r/programming/comments/1mr65a9/gluau_go_bindings_for_the_luau_programming/
datascience,"Weekly Entering & Transitioning - Thread 11 Aug, 2025 - 18 Aug, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",6,35,11-08-2025 09:31,AutoModerator,https://reddit.com/r/datascience/comments/1mn3338/weekly_entering_transitioning_thread_11_aug_2025/
datascience,"How different is ""Senior Data Analyst"" from ""Data Scientist""?","I often see Senior DA roles that seem focused on using R/Python for analysis (vs. Excel and Power BI), but don't have any insight into the day-to-day of theese roles. 

At the senior level, how different is Data Analyst from Data Scientist? ",83,39,16-08-2025 01:32,empirical-sadboy,https://reddit.com/r/datascience/comments/1mr8nwu/how_different_is_senior_data_analyst_from_data/
datascience,Suspicious ad,"Describe the results you want and then have ai manufacture those results for you... who's going to tell them that's not how science works ü§£

Disclosure: I did not read about their tool at all,I just that the advert sounded terribly bad.",66,7,15-08-2025 08:31,CorpusculantCortex,https://reddit.com/r/datascience/comments/1mqlp7d/suspicious_ad/
datascience,"Overfitting on training data time series forecasting on commodity price, test set fine. XGBclassifier. Looking for feedback","Good morning nerds, I‚Äôm looking for some feedback I‚Äôm sure is rather obvious but I seem to be missing. 

I‚Äôm using XGBclassifier to predict the direction of commodity x price movement one month the  the future. 

~60 engineered features and 3500 rows. 
Target = one month return > 0.001
 
Class balance is 0.52/0.48. Backtesting shows an average accuracy of 60% on the test with a lot of variance through testing periods which I‚Äôm going to accept given the stochastic nature of financial markets. 

I know my back test isn‚Äôt leaking, but my training performance is too high, sitting at >90% accuracy. 

Not particularly relevant, but hyperparameters were selected with Optuna.

Does anything jump out as the obvious cause for the training over performance?  


",84,34,14-08-2025 22:55,Its_lit_in_here_huh,https://reddit.com/r/datascience/comments/1mq737g/overfitting_on_training_data_time_series/
datascience,Would you jump jobs if you're in fear of a layoff?,"EDIT: Just looked and this new company has 2.5 stars out of 600 reviews on Glassdoor. Oof.

Currently based in the U.S., working remote, medium cost of living area. I make 90k a year and I'm the lead (and only) data scientist / frontend software dev for our area in the company. On top of data science/analyst stuff, I maintain/build our training website for around 500 employees (solo dev as well using React).

The down side? I work for Medicaid, and if you know what's going on in the United States you know Medicaid is having major cuts, and especially for 2026. We have laid off 300 people this year (so far). I was told ""You have nothing to worry about because your role is so niche"" but I still feel worried.

New job:

- Pay raise to 115k a year

- Still remote

- I would be working under my current boss who is transitioning to this new company (I have worked with him for 8 years, and the fact that my boss left this current job says something).

- 401k is comparable (3% match), health insurance is better and less cost, PTO is comparable.

- What I'm worried about: He is starting this new department from the ground up. I would be the only data/front-end website guy basically doing what I do in my current role. I'm worried the workload will be too much, or I'm not good enough to start from scratch. Feeling some imposter syndrome here.

Thanks for any insight here! This job I am currently at is fun, productive, and I love my team. But I am scared to death of layoffs. The company I am going to now has been around for 25 years, is growing a lot, and has much more ""lasting power"" in my opinion.",79,36,14-08-2025 21:14,tits_mcgee_92,https://reddit.com/r/datascience/comments/1mq4ai4/would_you_jump_jobs_if_youre_in_fear_of_a_layoff/
datascience,Time series with value dependent lag,"I build models of factories that process liquids. Liquid flows through the factory in various steps and sits in tanks. A tank will have a flow rate in and a flow rate out, a level, and a volume so I can calculate the residence time. It takes ~3 days for liquid to get from the start of the process to the end and it goes through various temperatures, separations, and various other things get added to it along the way. 

If the factory is in a steady state the residence times and lags are relatively easy to calculate. The problem is I am looking at 6 months worth of data and during that time the  rate of the whole facility varies and therefore the residence times vary. If the flow rate goes up residence time goes down. 

How would you adjust the lags based on the flow rates? Chunk the data into months and calculate the lags for each month then concat√©nate everything? Vary the lags and just drop the overlaps and gaps?",14,15,15-08-2025 04:14,big_data_mike,https://reddit.com/r/datascience/comments/1mqfubv/time_series_with_value_dependent_lag/
datascience,Copy-pasting jupyter notebooks is memory heavy on VSCode,"Currently for most of my work, I found out that copy-pasting jupyter notebooks and slightly modifying them is the most effective way to do my work. So basically I have a ipynb for every project I do every day.

However, some issues is that they can sometimes get a pretty big memory footprint especially when I have a lot of plots. Like around 1GB per notebook. So sometimes it takes several seconds to a minute to open some files on vscode. I was wondering if there's a way to optimize this?

  
I saw there's marimo and stuff. Wondering what you guys do.",32,17,14-08-2025 21:32,Affectionate_Use9936,https://reddit.com/r/datascience/comments/1mq4sfp/copypasting_jupyter_notebooks_is_memory_heavy_on/
datascience,Job market getting any better or nah?,I‚Äôve been staying in my role and refusing to leave for the last several years. I‚Äôm wondering if there‚Äôs any signs yet the job market is coming back yet or if we‚Äôre still stuck in the slog,79,67,14-08-2025 05:11,BB_147,https://reddit.com/r/datascience/comments/1mpkk2n/job_market_getting_any_better_or_nah/
datascience,How can I gain business acumen as a data scientist?,"I can build models, but can I build profits? That‚Äôs the gap I‚Äôm trying to close.

I‚Äôm doing my Master‚Äôs in Data Science with a BSc in Computer Science. My technical skills are strong, but I lack business acumen. In interviews, I‚Äôve noticed many questions aren‚Äôt just about models or algorithms, but about how those translate into profits or measurable business value.

Senior data scientists seem to connect their work to revenue, retention, or strategy with ease, while I still default to thinking in terms of accuracy and technical metrics. How did you learn to bridge that gap? Did you focus on general business knowledge, industry-specific skills, or hands-on projects?

I want to speak the ‚Äúlanguage of the business‚Äù so my work is not just technically solid but strategically impactful.",92,42,14-08-2025 01:14,Odd_Artist4319,https://reddit.com/r/datascience/comments/1mpei2b/how_can_i_gain_business_acumen_as_a_data_scientist/
datascience,"Research Data Scientists without heavy coding backgrounds (stats, econ, etc), has LLM's improved your workflow?","I remember for a while there were many CS folks saying that Data Science has become software engineering, and that if you aren't fluent in software engineering fundamentals then you're going to fall behind. It became enough of a popular rhetoric that people said they preferred to hire a coder with some math knowledge than a math person with some coding knowledge. 

As a Statistician that works in Research Data Science with an average level of coding experience, enough to write my own code in notebooks, but translating it into a fully fleshed Python module with classes and functions was much more difficult for me. For a while I thought my lack of advanced software engineering knowledge would become a crutch in my career and as someone with a busy personal life I didn't want to spend that much time learning these fundamentals. Then, my company rolled out LLM's integrated into the software we use, like Visual Studio. Suddenly I'm able to create fully fleshed out modules from my notebooks in a flash. I can ask the LLM to write unit tests to test out how my code processes data or test its various subfunctions. I can use it to code up various types of models quickly to compare results. Handing off my code to engineering in the form of a Python package wasn't such a pain anymore. 

Sure the LLM produces some weird results sometimes, and I do have to spend time making sure I ask it the correct things and/or cleaning up the code so that it works properly. But now I feel like that crutch I had is no longer present.",129,35,13-08-2025 22:35,jambery,https://reddit.com/r/datascience/comments/1mpa610/research_data_scientists_without_heavy_coding/
datascience,What should my job title be,"I‚Äôve been in my current role for ~5 months after finishing up my masters in geospatial data science. My official title is Energy Analyst, so essentially a data analyst role in the energy industry. 

I feel like the work I do is potentially beyond what is meant for the position (though I‚Äôm happy to be told otherwise if that‚Äôs not true) and am planning on asking for a title change and raise in the next few months. 

We have a weird set-up where we have a central IT team that supports ~12 implementation contractor teams that work with various utilities. The central IT team owns all of our data and does not allow any sort of read access or api to access data, and only exposes anything through SSRS reports. In theory, the IT team is meant to support a lot of our analytics, but historically they‚Äôve done a pretty bad job at that so I was hired into one of the distributed teams to run their analytics and build out an internal IT capacity. So far that has included the following:

- Recreating a database from the SSRS extracts. So far this is only a few tables in a sqlite3 db so nothing crazy. 
- Developing optimization models in pyomo to inform program design.
- Lots of ad hoc analysis and reporting. Most of this can be done with some filtering and group-bys but has also included some iterative proportional fitting and other kind of ‚Äòmedium difficulty‚Äô methods. 
- creating power bi dashboards as well as a couple java script maplibre-gl-js maps with complex symbology.
- we accept applications to our program via an online intake, where applicants fill out forms one by one. Most of these applicants submit tens to hundreds of these applications at once. I am working in parallel on a few different potential solutions to this: templates for batch uploading is the easy one, and a potential api integration to pull applications directly from applicant systems is another.
- looking into creating some llm-agents to automate very simply data extraction. I have already tried automating these processes via dom ids and such but haven‚Äôt gotten it to work reliably enough yet. My manager specifically asked for me to try agentic approaches to appease higher ups that we are implementing AI.

I‚Äôm not entirely sure where I fall in the landscape of data titles and would appreciate input. I mostly use python with a bit of power query and vanilla excel as well. Very little Java script (just for certain visualizations). Power bi. 

Edit to add- I also manage an intern-turned-part-time-employee that supports me in the above tasks basically at my own discretion ",6,10,14-08-2025 08:46,Tyrannosaurus_Secks,https://reddit.com/r/datascience/comments/1mpp8sv/what_should_my_job_title_be/
datascience,Getting Master's worth it with T5 Bachelor's?,"As a bit of background, I have 2 years of work experience as a Data Scientist, and I have a Bachelor's Degree in Mathematics from a 'top' University: think MIT/Harvard/Princeton.

I'm currently employed. Making about $105k in total comp. I have a feeling I could be doing better compensation wise and even task wise so I've been considering applying to more jobs. 

I've noticed a lot of job postings seem to have a minimum requirement of at least a Master's degree, but I'm sort of hesitant to pursue this route right now for a few reasons. For one, master's are expensive, and I don't want to quit my job and go into debt. Secondly, if I were to pursue an online Master's degree, I'm not sure the available options would increase my signal. For example, does a MIT Math Bachelor's -> Texas AM Master's Data Science really boost the resume?

The only reason I'd get a Master's is for my love of learning, and I'd pursue something theoretical ML oriented and maybe transition into a more research-heavy or even quant role. But I'm not feeling this is an imminent or necessary next step for me.

I'm not trying to be cocky; I'm just trying to get insight from more seasoned people in the field who might be closer to hiring expectations.",0,17,14-08-2025 23:00,Helloiamwhoiam,https://reddit.com/r/datascience/comments/1mq78jd/getting_masters_worth_it_with_t5_bachelors/
datascience,"When you edit the massive query someone sent you, forgot where you deleted something, and left a comma behind...",,131,8,11-08-2025 22:02,ElectrikMetriks,https://reddit.com/r/datascience/comments/1mnhsx7/when_you_edit_the_massive_query_someone_sent_you/
datascience,Using Experiment Tracking For Backtests,"I‚Äôve used MLFlow as a data scientist, but here it‚Äôs being used for managing algo trading backtests and I thought this was an awesome use case. (And these aren‚Äôt ML runs, this is testing a momentum strategy).",3,4,12-08-2025 17:26,Clicketrie,https://reddit.com/r/datascience/comments/1mo6ofm/using_experiment_tracking_for_backtests/
datascience,Catch-22 followup,"I'm following up on my post about ""Catch-22: learning R with projects""

Thank you to all those who responded. The replies were very reassuring.

After reading through the replies and reflecting on it, I realised the core of my struggle came from a specific fear that I would have to go through a rigorous coding interview, similar to what software engineers face.

I was picturing a scenario where I'd be given a problem and have to write perfect, memorised R code on the spot without any help. That pressure is what made me feel like I had to absorb every cheat sheet and learn all the syntax before I could even start a project. It created the syntax vs. projects Catch-22 that my original post was about.

For those who pivoted to data science or data analytics, did you have to go through some sort of coding interview or was it just like any other interview?",19,10,11-08-2025 21:13,DataAnalystWanabe,https://reddit.com/r/datascience/comments/1mnggxa/catch22_followup/
datascience,Databricks Freea course Recs,"Can anyone recommend a great free databricks catalog or otherwise course to level up as a DS using databricks itself? 

",5,3,11-08-2025 22:20,tinkinc,https://reddit.com/r/datascience/comments/1mniapg/databricks_freea_course_recs/
datascience,"Catch-22: Learning R through ""hands on"" Projects","

I often get told ""learn data science by doing hands-on projects"" and then I get all fired up and motivated to learn, and then I open up R.... And then I stare at a blank screen because I don't know the syntax from memory. 

And then I tell myself I'm going to learn the syntax so that I can do projects, but then I get caught up creating folders for each function of dplyr and the subfunctions of that and cheat sheets for this.

And then I come across the advice that I shouldn't learn syntax for the sake of learning syntax - I should do hands on projects.

I need projects to learn syntax and I need syntax to start doing projects.

________


Edit - Thank you so much to all of you who have replied and I would respond to each one of you but I don't want to sound like a parrot.

The reassurance that you don't have to have absorbed every R cheat sheet before being a professional Data Scientist/Analyst is very much appreciated. 

My assumption was these data analyst/scientist roles had coding-exams as part of the interview process, which is what stressed me out. Seeing some of you here as experienced analysts who still Google code is very relieving. I am very grateful for each response, and I read each one carefully.",45,31,11-08-2025 06:36,DataAnalystWanabe,https://reddit.com/r/datascience/comments/1mmzk4s/catch22_learning_r_through_hands_on_projects/
datascience,AI isn't taking your job. Executives are.,"If AI is ready to replace developers, why aren't developers replacing themselves with AI and just taking it easy at work?

I'm a Director at my company. I'm in the meetings and helping set up the tools that cost people their jobs. Here's how they work:

1. Claude AI writes some code

2. The code gets passed to a developer for validation

3. Since the developer's ""just validating"", he can be replaced with an overseas contractor that'll work for a fraction of the pay

We've tracked the tools, and we haven't seen any evidence that having Claude take a crack at the code saves anybody any time - but it does let us justify replacing expensive employees with cheap overseas contractors.

You're not getting replaced by AI.

Your job's being outsourced overseas.",1765,169,09-08-2025 16:43,takenorinvalid,https://reddit.com/r/datascience/comments/1mlmwk0/ai_isnt_taking_your_job_executives_are/
datascience,"Burnout, disillusionment, and imposter syndrome after 1 year in DS. Am I just an API monkey? Reality check needed.","Hey folks,

I am about a year into my first data science job. It took roughly a year and more than 400 applications to land it, so the idea of another long search is scary.

Early on I worked with an internally built causal AI model that captures relationships for further analysis. I did not build the model. I ran experiments to make it more explainable and easier for others to use. I also built data orchestration pipelines using third party tools that are common in industry and cloud providers like AWS and GCP.

The last six months have shifted to LLM and NLP work. A lot of API calls, large text analysis. The next six months look even more LLM heavy since I am leading an internal tool build.

On paper there are wins:
- I have led projects and designed tools from scratch.
- My communication and client skills have improved.


My concerns:

- I am not doing much classical DS or rigorous modeling.
- LLM work often feels like API wrangling rather than technical depth.
- Work life balance is rough with frequent weekends.
- Even with a possible 5 to 10 percent raise (possibly within the next 6 months), the work likely stays the same.

I feel imposter syndrome and worry I am behind my peers on fundamentals and interview depth. I‚Äôm so burned out and honestly can‚Äôt tell if I‚Äôm just being a negative Nancy or if my concerns are legit. Am I shortchanging myself by thinking that I'm just not skilled enough? Idk


What I would love input on:

Am I building valuable skills for the DS market, or am I narrowing myself too much?

What types of companies or industries might value this mix of causal modeling, LLM work, and consulting style analysis?

If I want to keep doors open for more traditional DS or ML roles, what should I focus on learning now?

Portfolio ideas I can ship from my current work that would impress a hiring manager?

Would you ride out six months to finish the tool and try for a promotion, or start looking sooner?

Honest takes are very welcome.

",112,42,09-08-2025 22:26,RookFlame4882,https://reddit.com/r/datascience/comments/1mluc12/burnout_disillusionment_and_imposter_syndrome/
datascience,Business focused data science,"As a microbiology researcher, I'm far away from the business world. I do more -omics and growth curves and molecular techniques, but I want to move away from biology.

I believe the bridge that can help me do that is data. I have got experience with R and excel. I'm looking at learning SQL and PowerBI.

But I want to do it away from biology. The problem is, if I was to go from the UK, as a PhD microbiologist, and approach GCC consulting/business analyst recruiters, I get the sense that they'd scoff at me for thinking too highly of my ""transferrable skills"" and tell me that I don't have experience in the world of business.

How would I get myself job-ready for GCC business-focused data science roles. Is there anyone out there that has made the switch that can share some advice?

Thanks in advance",37,28,10-08-2025 01:10,DataAnalystWanabe,https://reddit.com/r/datascience/comments/1mly9hm/business_focused_data_science/
datascience,Just bombed a technical interview. Any advice?,"I've been looking for a new job because my current employer is re-structuring and I'm just not a big fan of the new org chart or my reporting line. It's not the best market, so I've been struggling to get interviews. 

But I finally got an interview recently. The first round interview was a chat with the hiring manager that went well. Today, I had a technical interview (concept based, not coding) and I really flubbed it. I think I generally/eventually got to what they were asking, but my responses weren't sharp.* It just sort of felt like I studied for the wrong test. 

How do you guys rebound in situations like this? How do you go about practicing/preparing for interviews? And do I acknowledge my poor performance in a thank you follow up email?

*Example (paraphrasing): They built a model that indicated that logging into a system was predictive of some outcome and management wanted to know how they might incorporate that result into their business processes to drive the outcome. I initially thought they were asking about the effect of requiring/encouraging engagement with this system, so I talked about the effect of drift and self selection on would have on model performance. Then they rephrased the question and it became clear they were talking about causation/correlation, so I talked about controlling for confounding variables and natural experiments.",74,54,09-08-2025 02:10,gonna_get_tossed,https://reddit.com/r/datascience/comments/1ml6fxs/just_bombed_a_technical_interview_any_advice/
datascience,Resources/tips for someone brand new to model building and deployment in Azure?,"Context: my current company is VERY (VERY) far behind, technologically. Our data isn't that big and currently resides in SQL Server databases, which I query directly via SSMS.

Whenever a project requires me to build models, my workflow would generally look like:

1. Query the data I need, make features, etc. from SQL Server.
2. Once I have the data, use Jupyter Notebooks to train/build models. 
3. Use best model to score dataset.
4. Send dataset/results to stakeholder as a file.

My company doesn't have a dedicated Dev team (on-shore, at least) nor a DE team. And this workflow works to make ends meet. 

Now my company has opened up Azure accounts for me and my manager, but neither one of us have developed anything in it before.

Microsoft has PLENTY of documentation, but the more I read, the more questions I have, and I feel like my time will be spent reading articles rather than getting anything done.

It seems like quite a shift from doing everything ""locally"" like what we have been doing to actually using cloud resources. So does anyone have any tips/guides that are beginner-friendly where I can do my entire workflow in the cloud?",23,7,08-08-2025 21:44,redditisthenewblak,https://reddit.com/r/datascience/comments/1mkzhvp/resourcestips_for_someone_brand_new_to_model/
datascience,How would you visualize or analyze movements across a categorical grid over time?,"I‚Äôm working with a dataset where each entity is assigned to one of N categories that form a NxN grid. Over time, entities move between positions (e.g., from ‚ÄúN1‚Äù to ‚ÄúN2‚Äù).

Has anyone tackled this kind of problem before? I‚Äôm curious how you‚Äôve visualized or even clustered trajectory types when working with time-series data on a discrete 2D space.",11,11,08-08-2025 10:42,Proof_Wrap_2150,https://reddit.com/r/datascience/comments/1mkmjje/how_would_you_visualize_or_analyze_movements/
datascience,How do you analyse unbalanced data you get in A/B testing?,"Hi 
I have two questions related unbalanced data in A/B testing. Would appreciate resources or thoughts. 

1. Usually when we perform A/B testing, we have 5-10% in treatment, after doing power analysis we get the sample size needed, we run tge experiment, by the time we get required sample size for treatment we get way more control samples, so now when we analyse, which samples do we keep in control group? For example by the time we collect 10k samples from treatment we might get 100k samples of control. So what to do now before performing t-test or any kinds of test? 
 (In ML we can downsample or over sample but what to do in causal side) 

2. Again similar question Lets say we are performing test on 50/50 but if one variant get way more samples as more ppl come through that channel and common for users, hiw do we segment users such as way? And again which samples we keep once we get way more sample than needed? 

I want to know how it is tackeled in day to day, and this thing happen frequently right? Or am i wrong? 

Also, what if you get sample size before expected time? (Like was thinking to run them for 2 weeks but got the required size in 10 days) Do you stop the experiment and start analyzing? 

Sorry for this dumb question but i could not find good answers and honestly don‚Äôt trust chat gpt much as many time it hallucinates in this topic. 

Thanks!",29,26,08-08-2025 03:51,Starktony11,https://reddit.com/r/datascience/comments/1mkdy7a/how_do_you_analyse_unbalanced_data_you_get_in_ab/
datascience,What elective course should I take,"Hey all,

About to start my last semester for my masters in computer science, with a concentration in AI. I‚Äôm a veteran data scientist, this is more of a vanity degree and an ability to say ‚Äúyes I do have a masters degree‚Äù on a job application, but I have enjoyed the studying overall. 

I have room for one elective class, and I‚Äôm trying to decide what I should take. None of them that fit my schedule seem particularly appealing:

- data analysis: hyper redundant given my background
- computer networks: possibly useful, but I‚Äôd much rather learn something like distributed systems
- intro to cybersecurity: maybe good, but seems like it would be mostly terminology and not so much a deep dive on anything 
- object oriented design: could be nice for refining my actual design choices, but programming seems like the least valuable skill to upskill on in computer science now (as compared to, say, cloud computing, which is and will continue to be good to know). 

It‚Äôs not exactly the most pressing choice, but I thought I‚Äôd throw it to Reddit, and see if anyone has a strong opinion on what‚Äôs good to learn to augment my ML/AI background

Edit: okay I think you people convinced me. Object oriented design it is! Which sounds a whole lot better than computer networks, that‚Äôs for sure. ",6,18,07-08-2025 23:45,Pristine-Item680,https://reddit.com/r/datascience/comments/1mk7lpa/what_elective_course_should_i_take/
datascience,"""SemiAuto"" Fully Automated Machine Learning Lifecycle by Just API Calling","So for the last 4 months I have been working on this project which was first supposed to be a upgrade of AutoML, but I later recognised it's potential.

This project could be one of the best things in ML reasearch, This project is just that good.

For context, I have the knowledge around ML for about 1.5 years now and thanks to the tools available, I have been able to build a grand project like this,

The Project's or you can say the Tool name is 'SemiAuto', A full fledged ML lifecycle Automation tool. It has 3 microservice, Regression, Classification, and Clustering.

I have completely build the Version 1 of this project.


It has 6 parts, First ingest the Data.csv file and the target column.

Second choose whatever preprocessing you want to and apply them.

Third use feature tools to build new features and then SHAP to select the amount of features you want.

Fourth choose any algorithm you want with the hyper params and build the model.

Fifth choose the optimization technique and get an optimised model.

At last, get the report, model.pkl, and processor.pkl and use them wherever you want.


As of why this project would be extremely good in research as researchers needs to test with different techniques and different models to get the best thing out and this tool provides that,

This tool will in a semiautomatic way can fully do each and everything by itself, no coding required.

The version 2 of this project is in production and I are introducing much more than the previous version,
For example, Parallel model building, Simple Ensemble design and Staged Ensemble design.

And also the thing that no one as of today has ever implemented in their ML automation tool, Meta-Heuristics Algorithms for feature selection.


Version 2 will be one of the most mind blowingly incredible release of the SemiAuto",0,6,08-08-2025 13:02,Damp_Out,https://reddit.com/r/datascience/comments/1mkov0u/semiauto_fully_automated_machine_learning/
datascience,"Seeking Meaningful, Non-Profit Data Volunteering Projects",,26,9,06-08-2025 14:26,Astherol,https://reddit.com/r/datascience/comments/1mizivg/seeking_meaningful_nonprofit_data_volunteering/
datascience,How can I *give* a good data science/machine learning interview?,"I'm around 6 months into my first non intern job and am the only data scientist/MLE in my company. My company has decided they want to bring on some much needed help (thank god) and want me to do ""the more technical side"" of the interview (with others taking care of the behavioral etc)

I do have some questions in mind specific to my job for what I want in a colleague but I still feel a bit underprepared. My plan is to ask the 'basic' questions that I got asked in every interview (classification vs clustering, what is r^2, etc) before asking them how they would solve some of the problems I'm actually working on

But like that's all I have in the pipeline at the moment, and I'd really like to avoid this becoming the blind interviewing the blind moment.  

Does anyone have any good tips on how to do the interviews, what to look for or what to include? Thank you!!!!

EDIT: In reply to the DMs, we are not accepting any new applicants at this time üòÖ",171,39,04-08-2025 22:12,ProbaDude,https://reddit.com/r/datascience/comments/1mhikh4/how_can_i_give_a_good_data_sciencemachine/
datascience,Share your thought on open source alternative for data robot,Data robot is the market leader when it comes to enterprises data science project life cycle management. But there is no open source alternative available in the market right now. What are the chances of getting a good adoption if I can build the open source alternative of data robot?,0,8,06-08-2025 06:51,vishal-vora,https://reddit.com/r/datascience/comments/1miresg/share_your_thought_on_open_source_alternative_for/
datascience,How I built and deployed a GenAI app in minutes using open‚Äësource tools + Azure,"Hey everyone building AI apps always felt like a massive undertaking. So much code, setup, server stuff. I recently tried something different and launched a working GenAI app in just under 15 minutes. I used Dify AI (an open‚Äësource platform) to design the app and Microsoft Azure to deploy it.

What I learned:
‚Ä¢ No heavy DevOps or managing servers
‚Ä¢ Very user‚Äëfriendly interface‚Äîjust plug in your AI logic
‚Ä¢ Scales automatically via Azure cloud resources

Would love to hear if anyone‚Äôs tried Dify AI or other open‚Äësource builders for AI‚Äîand what challenges you faced!

Full details in this write‚Äëup:
https://medium.com/@techlatest.net/launch-genai-apps-in-minutes-with-techlatest-dify-ai-on-azure-cloud-platform-8307bccf4aed

Happy to answer questions or breakdown steps if interested üòä",0,4,05-08-2025 21:00,techlatest_net,https://reddit.com/r/datascience/comments/1miccmb/how_i_built_and_deployed_a_genai_app_in_minutes/
datascience,"Weekly Entering & Transitioning - Thread 04 Aug, 2025 - 11 Aug, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",7,56,04-08-2025 09:31,AutoModerator,https://reddit.com/r/datascience/comments/1mh3i7n/weekly_entering_transitioning_thread_04_aug_2025/
datascience,Personal projects and skill set,"Hi everyone,
I was just wondering how do you guys specify personal acquired skills from your personal projects in your CV.
I‚Äôm in the midst of a pretty large project - end to end pipeline for predicting real time probabilities of winning chances in a game. This includes a lot of tools, from scraping, database management (mostly tables creations, indexing, nothing DBA-like), scheduling, training, prediction and data drift pipelines, cloud hosting, etc. and I was wondering how I can specify those skills after I finish my project, because I do learn tons from this project. To say I‚Äôm using some of those tools in my current job is not entirely right so‚Ä¶

What would you say?
Cheers.",22,11,04-08-2025 01:26,indie-devops,https://reddit.com/r/datascience/comments/1mgsshu/personal_projects_and_skill_set/
datascience,Built this out of pure laziness for all my Feature engineering/model training jobs,"Built this out of pure laziness 
A lightweight Telegram bot that lets me: 
- Get Databricks job alerts
- Check today‚Äôs status
- Repair failed runs
- Pause/reschedule ,
All from my phone.
No laptop. No dashboard. Just / Commands.",58,10,03-08-2025 15:20,Anu_Rag9704,https://reddit.com/r/datascience/comments/1mgfcke/built_this_out_of_pure_laziness_for_all_my/
datascience,Is there a term for internal processing vs data that needs to be stakeholding/customer facing?,"For example I had my physical credit card stolen. I was trying to get information from the CC company about when the card was used so that the local PD could check security cameras. (We thought it was particular person so they made a little bit more effort). When I called the credit card company, the customer service person started telling me these random times that made no sense and I realized he was reading the wrong column which were basically the time the charge was converted from ‚Äú?‚Äù to an actual money transfer. I assume to him it gave insight into how to refund each charge so ‚Äúrelvant‚Äù just not ‚Äúrelvant‚Äù information I would ever need to know.

Two years later, I am setting up a model with my team and we batting around terms to differentiate between data like these dates & times that are relvant but are not relvant un-manipulated or laid bare for the stakeholder to see visualized or be discussed outside of our team.

You can hear the inevitable pause from a team member every time the concept comes up as they attempt a new word.  While it was amusing it‚Äôs starting to eat at me. Any ideas?",4,4,04-08-2025 04:38,CleanDataDirtyMind,https://reddit.com/r/datascience/comments/1mgxgpl/is_there_a_term_for_internal_processing_vs_data/
datascience,What would be a better job Position ? Data Scientist or AI/ML Engineer.,,0,18,04-08-2025 16:01,SharePlayful1851,https://reddit.com/r/datascience/comments/1mh9tvo/what_would_be_a_better_job_position_data/
datascience,Algorithm Idea,This sudden project has fallen on my lap where I have a lot of survey results and I have to identify how many of those are actually done by bots. I haven‚Äôt see what kind of data the survey holds but I was wondering how can I accomplish this task. A quick search points me towards anomaly detections algorithms like isolation forest and dbscan clusters. Just wanted to know if I am headed in the right direction or can I use any LLM tools. TIA :) ,1,18,04-08-2025 04:32,NervousVictory1792,https://reddit.com/r/datascience/comments/1mgxbio/algorithm_idea/
datascience,Hi! i am a junior dev need advice regarding fraud/risk scoring (not credit) on my rules based fraud detection system.,"so i our team has developed a rules based fraud detecton system....now we have received a new requirement that we have to score every transaction as how much risky or if flagged as fraud how much fraud it is.

i did some research and i found out its easier if it is a supervisied operation but in my case i wont be able to access prod transaction data due to policy.

now i have 2 problems data which i guess i have to make a fake one.

2nd how to score i was thinking of going witb regression if i keep my target value bete 0 and 1 but realised that the model can predict above that
then thought of classification and use predict_proba() to get prediction probability.

or isolation forest

till now thats what i bave you thought what else shoudl i consider any advices or guidance to set me in the right path so i dont get any rework
",0,5,04-08-2025 00:49,1_plate_parcel,https://reddit.com/r/datascience/comments/1mgrvsh/hi_i_am_a_junior_dev_need_advice_regarding/
datascience,Using a hybrid role in job title (Data Science and Engineer),"I have an BS and MS in data science and got hired as a data analyst for a small ish scale company for about a year now as my first job. I'm the only data person in the entire company and I've been wanting to transition into a data science focused role for awhile, so I have been using DS and DE principles at every opportunity to boost my resume. This has ended up extending far beyond the typical DA responsibilities as I have been utilizing a lot of stats modeling and predictive analytics over company data/KPIs, using MLOps occasionally, as well as building ETL pipelines, managing the internal DBMS and streamlining data acquisition through RESTful APIs with contracted third parties. I still do excel monkey work/tableau dashboards along with this.

Management ended up taking notice and since nobody in the building has any familiarity with data science/tech, they have asked me to rewrite my job description including my job title as a semi promotion. Since I have been working as a bit of a hybrid between DS and DE I am wondering if I should put the new contracted job title as a hybrid role (e.g. Data Science Engineer) or just pick one? My department head has suggested the title of Data Architect but I don't really think that aligns with my job responsibilities and it's also a senior sounding position which feels strange to take on considering I've only been in the industry for a year.",53,17,01-08-2025 23:52,pokelord13,https://reddit.com/r/datascience/comments/1mf44ek/using_a_hybrid_role_in_job_title_data_science_and/
datascience,How to convert data to conceptual models,"I am not sure if I am in the right subreddit, so please by patient with me.

I am working on a tool to reverse-engineer conceptual models from existing data. The idea is you take a legacy system, collect sample data (for example JSON messages communicated by the system), and get a precise model from them. The conceptual model can be then used to develop new parts of the system, component replacements, build documentation, tests, etc...

One of the open issues I struggle with is the fully-automated conversion from 'packaging' model to conceptual model.

When some data is uploaded, it's model reflects the packaging mechanism, rather than the concepts itself. For example. if I upload JSON-formatted data, the model initially consists of objects, arrays, and values. For XML, it is elements and attributes. And so on.

[JSON messages consist of objects, arrays, and values](https://preview.redd.it/rq6k13ej2egf1.png?width=737&format=png&auto=webp&s=415800ea39e0b408f91124f5d03fab02b631e75e)

I can convert the keys, levels, paths to detect concepts and their relationships.  It can look something like this:

[Data structures converted to concepts](https://preview.redd.it/r1d2ti683egf1.png?width=695&format=png&auto=webp&s=0927e6222a90412d7dd5b722fdb43ad07b49e027)

  
The issue I am struggling with is that this conversion is not straightforward. Sometimes, it helps to use keys, other times it is better to use paths. For some YAML files, I need to treat the keys as values (typically package.yaml samples).

Did anyone tried to convert data to conceptual models before? Any real-word use cases?

Is there any theory at least about the reverse direction - use conceptual model and map it into XML schema / JSON schema / YAML ... ?

Thanks in advance.",9,6,01-08-2025 16:49,JumbleGuide,https://reddit.com/r/datascience/comments/1mets4m/how_to_convert_data_to_conceptual_models/
datascience,Why is there no Cursor/Windsurf for Notebooks or Google Collab?," Last week, I tried Windsurf to build a web application and OMG my world was changed. I have used AI tools before but having an agent that implements the code for you is a game changer, my productivity probably went up x5 or x10 times. 

This made me think why is there nothing like this for a data scientist workflow? I know you can do notebook markdown but it is still not the same because Cursor cannot see outputs of your graphs. Also, this tool wouldn‚Äôt work on Google Collab where I have access to powerful GPUs. 

Now, imagine if you have a tool that goes from a prompt ‚Äúmake the predictive model to predict customer churn‚Äù and instead of something like Chatgpt giving you one slob of generic BS that will definitely give out an error, an agent goes and executes each cell one by one: making plots, studying the data, modifying the outliers etc. and adjusting the plan as it goes before finally making a few models and testing them. Basically, the standard data science workflow. 

I would like to build something this (I have no idea how yet lol) if there is interest in this community. What do you guys think? Those of you who are working in the field, would you actually use it? 

Also, if someone wants to build it with me, DM me. ",6,40,31-07-2025 23:46,giantwaterwithice,https://reddit.com/r/datascience/comments/1me934o/why_is_there_no_cursorwindsurf_for_notebooks_or/
datascience,Generative AI shell interface for browsing and processing data?,"So vibe coding is a thing, and I'm not super into it.

However, I often need to write little scripts and parsers and things to collect and analyze data in a shell environment for various code that I've written.  It might be for debugging, or just collecting production science data.  Writing that shit is a real pain, because you need to be careful about exceptions and errors and folder names and such.

Is there a way to do ""vibe data gathering"" where I can ask some LLM to write me a script that does a number of things like open up a couple thousand files that fit various properties in various folders, parse them for specific information, then draw say a graph?  ChatGPT can of course do that, but it needs to know the folder structure and examine the files to see what issues there are in collecting this information.  Any way I can do this without having to roll my sleeves up?",0,8,01-08-2025 09:07,Minotaar_Pheonix,https://reddit.com/r/datascience/comments/1mem3t5/generative_ai_shell_interface_for_browsing_and/
datascience,My take on the Microsoft paper,"I read the paper myself (albeit pretty quickly) and tried to analyze the situation for us Data Scientists.

The jobs on the list, as you can intuitively see (and it is also explicitly mentioned in the paper), are mostly jobs that require writing reports and gathering information because, as the paper claims, AI is good at it.

If you check the chart present in the paper (which I linked in this post), you can see that the clear winner in terms of activities done by AI is ‚ÄúGathering Information‚Äù, while ‚ÄúAnalyzing Data‚Äù instead is much less impacted and also most of it is people asking AI to help with analysis, not AI doing them as an agent (red bar represents the former, blue bar the latter).

It seems that our beloved occupation is in the list mainly because it involves gathering information and writing reports. However, the data analysis part is much less affected and that‚Äôs just data analysis, let alone the more advanced tasks that separate a Data Scientist from a Data Analyst.

So, from what I understand, Data Scientists are not at risk. The things that AI does do not represent the actual core of the job at all, and are possibly even activities that a Data Scientist wants to get rid of.

If you‚Äôve read the paper too, I‚Äôd appreciate your feedback. Thanks!",170,23,31-07-2025 00:27,FinalRide7181,https://reddit.com/r/datascience/comments/1mdf6fn/my_take_on_the_microsoft_paper/
datascience,Microsoft just dropped a study showing the 40 jobs most affected by Al and the 40 that Al can't touch (yet).,,398,160,30-07-2025 18:07,timusw,https://reddit.com/r/datascience/comments/1md5gvk/microsoft_just_dropped_a_study_showing_the_40/
datascience,Working remote,"hey all 
i‚Äôve been a data scientist for a while now, and i‚Äôve noticed my social anxiety has gotten worse since going fully remote since covid. i love the work itself - building models, finding insights etc, but when it comes to presenting those insights, i get really anxious. it‚Äôs easily the part of the job i dread most.

i think being remote makes it harder. less day-to-day interaction, fewer casual chats - and it just feels like the pressure is higher when you do have to speak. imposter syndrome also sneaks in at time. tech is constantly evolving, and sometimes i feel like i‚Äôm barely keeping up, even though i‚Äôm doing the work.

i guess i‚Äôm wondering:
	‚Ä¢	does anyone else feel this way?
	‚Ä¢	have you found ways to make communications feel less overwhelming?

would honestly just be nice to hear from others in the same boat. thanks for reading.",118,41,30-07-2025 21:23,itssdgm,https://reddit.com/r/datascience/comments/1mdaa40/working_remote/
datascience,FIGMA? Is the tech industry back?,"Have you guys heard of this IPO? Stock tripled on debut. What does this company do? 

I feel like you tech bros might have a come back soon fyi ",0,6,31-07-2025 23:45,Aristoteles1988,https://reddit.com/r/datascience/comments/1me91rq/figma_is_the_tech_industry_back/
datascience,I built a free job board that uses ML to find you ML jobs,"**Link:**¬†[**https://www.filtrjobs.com/**](https://www.filtrjobs.com/)

I was frustrated with irrelevant postings relying on keyword matching so i built my own for fun

I'm doing a semantic search with your jobs against embeddings of job postings prioritizing things like working on similar problems/domains

The job board fetches postings daily for ML and SWE roles in the US.

It's¬†**100% free with no ads**¬†for ever as my infra costs are $0

I've been through the job search and I know its so brutal, so feel free to DM and I'm happy to give advice on your job search

My resources to run for free:

* Low cost VPS with postgres for hosting
* [modal.com](http://modal.com) for free cron jobs (30$/mo of free GPU usage)
* free cerebras LLM parsing (using llama 3.3 70B which runs in half a second - 20x faster than gpt 4o mini)
* Gemini flash for free job description parsing. I use about 3M tokens a day
* Using posthog and sentry for monitoring (both with generous free tiers)

",3,9,31-07-2025 05:01,_lambda1,https://reddit.com/r/datascience/comments/1mdm12b/i_built_a_free_job_board_that_uses_ml_to_find_you/
datascience,Model Governance Requests - what is normal?,"I‚Äôm looking for some advice. I work at a company that provides inference as a service to other customers, specifically we have model outputs in an API. This is used across industries, but specifically when working with Banks, the amount of information they request through model governance is staggering.

I am trying to understand if my privacy team is keeping things too close to the chest, because I find that what is in our standard governance docs, vs the details we are asked, is hugely lacking. It ends up being this ridiculous back and forth and is a huge burn on time and resources. 


Here are some example questions:

* specific features used in the model 

* specific data sources we use

* detailed explanations of how we arrived at our modeling methodology, what other models we considered, the results of those other models, and the rationale for our decision with a comparative analysis

* a list of all metrics used to evaluate model performance, and why we chose those metrics

* time frame for train/test/val sets, to the day

I really want to understand if this is normal, and if my org needs to improve how we report these out to customers that are very concerned about these kinds of things (banks). Are there any resources out there showing what is industry standard? How does your org do it?

Thanks",6,13,30-07-2025 21:37,#NAME?,https://reddit.com/r/datascience/comments/1mdan3p/model_governance_requests_what_is_normal/
datascience,Python Summer Party (free!): 15-day coding challenge for Data folks,"I‚Äôve been cooking up something fun for the summer.. A Python-themed challenge to help Data Scientists & Data Analysts practice and level up their Python skills. Totally free to play!

It‚Äôs called **Python Summer Party**, and it runs for 15 days, starting August 1.

Here‚Äôs what to expect:

* One Python challenge + 3 parts per day
* Focused on Data skills using *NumPy*, *Pandas*, and regular Python
* All questions based on real companies, so you can practice working with real problems
* Beginner to intermediate to advanced questions
* AI chat to help you if you get stuck
* Discord community (if you still need more help)
* A chance to win 5 free annual Data Camp subscriptions if you complete the challenges
* Totally free

I built this because I know how hard it can be to stay consistent when you‚Äôre learning alone. Plus, when I was learning Python I couldn't find questions that allowed me to apply Python to realistic business problems.

So this is meant to be a light, motivating way to practice and have fun with others. *I even tried to design it such that it's cute & fun.*

Would love to have you join us (and hear your feedback if you have any!) 

[www.interviewmaster.ai/python-party](http://www.interviewmaster.ai/python-party)",83,25,30-07-2025 02:32,askdatadawn,https://reddit.com/r/datascience/comments/1mcngiy/python_summer_party_free_15day_coding_challenge/
datascience,Since when did ‚Äúmeets‚Äù expectations become a bad thing in this industry?,"I work at a pretty big named company on west coast. It is pretty shocking to see that in my company anyone who gets ‚Äúmeets‚Äù expectations have not been getting any salary increments, not even a dollar each year. I‚Äôd think if you are meeting expectations, it means you are holding up your end of the deal and it shouldn‚Äôt be a bad thing. But now, you actually have to exceeds expectations to get measly 1% salary raises and sometimes to just keep your job.

Did this used to happen pre covid as well?",224,54,29-07-2025 20:05,Lamp_Shade_Head,https://reddit.com/r/datascience/comments/1mcd3n5/since_when_did_meets_expectations_become_a_bad/
datascience,Does a Data Scientist need to learn all these skills?,"* Strong knowledge of Machine Learning, Deep Learning, NLP, and LLMs.
* Experience with Python, PyTorch, TensorFlow.
* Familiarity with Generative AI frameworks: Hugging Face, LangChain, MLFlow, LangGraph, LangFlow.
* Cloud platforms: AWS (SageMaker, Bedrock), Azure AI, and GCP
* Databases: MongoDB, PostgreSQL, Pinecone, ChromaDB.
* MLOps tools, Kubernetes, Docker, MLflow.

I have been browsing many jobs and noticed they all are asking for all these skills.. is it the new norm? Looks like I need to download everything and subscribe to a platform that teaches all these lol (cries in pain).",349,172,29-07-2025 10:48,CableInevitable6840,https://reddit.com/r/datascience/comments/1mc2zaz/does_a_data_scientist_need_to_learn_all_these/
artificial,AI vibes over time,,38,16,17-08-2025 18:55,katxwoods,https://reddit.com/r/artificial/comments/1msqv3g/ai_vibes_over_time/
artificial,So this is Zuck's vision for AI,,84,25,17-08-2025 12:54,MetaKnowing,https://reddit.com/r/artificial/comments/1mski42/so_this_is_zucks_vision_for_ai/
artificial,We‚Äôre building more homes for AIs than humans,,63,6,17-08-2025 13:49,MetaKnowing,https://reddit.com/r/artificial/comments/1msldmx/were_building_more_homes_for_ais_than_humans/
artificial,ChatGPT - One productive meeting,,19,3,17-08-2025 13:15,Confusedparents10,https://reddit.com/r/artificial/comments/1mskua7/chatgpt_one_productive_meeting/
artificial,YouTube using AI to Alter videos without notification to creators or viewers (reducing quality and then upscaling),"Video source: https://youtu.be/86nhP8tvbLY?si=qCw8un0e85D3PVzb

This creator spotted this in his own and in other creators' videos and raises his concerns",36,6,17-08-2025 07:05,Future_Usual_8698,https://reddit.com/r/artificial/comments/1mse41o/youtube_using_ai_to_alter_videos_without/
artificial,Autonomous Agents Crawling the Web + Recall-Style Browser Encyclopedia = Research Superpowers - and New Challenges,"
**TL;DR:** Combine a web-browsing autonomous agent (one that can click, scroll, and interact) with a browser-integrated memory/summary tool (like Recall) and you get near-autonomous research: the agent finds sources and the capture tool ingests summaries and builds a shareable knowledge graph. This multiplies research throughput but also externalizes memory and critical thinking - creating powerful productivity gains and concentrated misinformation risks. Pros and Cons list, future implementation, and Sources in comments below (might take me a bit as I‚Äôll have to embed each raw link even though I have them all at the ready to comment, unsure as I‚Äôm new to posting‚Äîwill find out soon I guess)

**Side note:** Funnily enough I came across Recall from Matt Wolfe‚Äôs latest video, which Recall was a sponsorship, great video on related and recent AI news too btw‚Äîrecommend. Recall deal on his vid, don‚Äôt know if I can put it here, feel like I‚Äôm already treading dangerously around automod.

To *preface* this topic, I essentially had a ***‚ÄúEureka!‚Äù*** moment‚Äîa idea to combine Agentic AI research + Recall‚Äôs data collection workflow. I put down my thoughts messily in a notes app‚Äîbefore having ChatGPT help organize those thoughts reasonably (replaced some words and sections, but mostly changed the style as it irked me the wrong way), also allowed its own idea on examples, a bit on the section of Cons at the two last parts, and what future implementation could look like. I‚Äôm very interested to hear your thoughts on this topic).


**What I stumbled on and Brainstormed:**
There are browser-based tools that automatically capture and summarize pages, videos, transcripts, and notes into a personal, searchable knowledge base like ***Recall.*** These tools also surface contextual links and let you chat (recent feature‚ÄîLLM for Recall) with the data they‚Äôve ingested. Free plan is restricted to ***10 content summaries & chats:** YouTube, Podcasts, PDFs, articles and more on a monthly basis, but it does have unlimited ‚Äúread-it-later storage‚Äù, and unlimited ‚Äúpersonal notes,‚Äù which basically is just your notes that you already have saved from summaries or of your own writing.


Separately, several organizations are shipping browser-capable **autonomous agents** that can act on the web on your behalf - browsing, filling forms, extracting data, and multi-step reasoning (OpenAI‚Äôs agent initiatives/Operator, Google‚Äôs Project Mariner, etc. Side note because I remembered and wanted to double check: Project Mariner from what I could find can‚Äôt perform tasks on your computer for now, *only browser*‚Äîunlike OpenAI‚Äôs Operator, but that‚Äôs fine as it seems like Recall is also a extension, not only a website tool or separate browser like I originally thought.


**The combined idea - aka: system architecture**

	1.	**Execution layer** - Autonomous agent: you give a high-level research directive; the agent opens pages, clicks, follows links, and submits forms.

	2.	**Ingestion & processing** - Browser memory tool: while the agent browses, a browser extension or capture API saves pages, transcripts, and one-click summaries into a personal **KB** (***Knowledge Base, aka: Central Repository area***). This produces structured notes, metadata, and connections.

	3.	**Organization** - Knowledge graph/mind map: the memory tool auto-categorizes content, detects related items, and builds a non-linear map (tags, links, clusters).

	4.	**Interface** - LLM query & synthesis: a conversational LLM layer sits atop the KB and can answer questions, synthesize insights from the captured corpus plus its general knowledge (most likely limited), and generate drafts or proposals. I couldn‚Äôt explicitly find what LLM they use or if it‚Äôs a new, in-house one. In one of their docs discussion about their chatbot they mention ChatGPT by essentially saying how it‚Äôs great that you can talk with it about stuff on the internet, but with Recall, it‚Äôs specifically tailored to any info you have saved in Recall‚Äôs application. The mention could hint at use but uncertain.


*Okay, moving on* ‚Äî>


**Example workflow:**
You ask an agent to ‚ÄúResearch recent climate policy changes in country X and produce a one-page summary with primary sources.‚Äù The agent runs for hours; finds official bills, news, think-tank analyses, and public datasets while the Agent works with Recall extension (the agent clicking through) to auto-summarize what source you‚Äôre on (they are still expanding what sources it can summarize, they also listen to customer feedback and are constantly improving) before it builds a **shared mind map.** You then can ask the LLM in Recall to synthesize the stored notes into an executive summary and annotate uncertainty or conflicting claims.


**Why this is powerful**

	‚Ä¢	Speeds up data gathering and triage by orders of magnitude.   
	‚Ä¢	Produces immediately shareable, searchable knowledge artifacts (summaries & graph).  


**Why this is scary/cautionary**

	‚Ä¢	You outsource not only searching but selective judgment and memory. If the agent chooses biased or low-quality sources, the captured KB looks authoritative even if it isn‚Äôt.  
	‚Ä¢	Single-point failure: A well-organized but erroneous knowledge graph is more persuasive and more reproducible than raw, scattered misinformation.
	‚Ä¢	Automation of synthesis increases scale at which mistakes propagate (easy sharing, rapid downstream use).
	‚Ä¢	Privacy, consent, and data-exfiltration vectors multiply when agents act across accounts or site interactions.   


**Concrete safeguards I‚Äôd want before using this in production**

	‚Ä¢	Explicit provenance tracking on every captured node (URL, timestamp, author, capture method).
	‚Ä¢	Human-in-the-loop verification checkpoints for high-impact summaries.
	‚Ä¢	Rate limits and domain whitelisting for agent browsing.
	‚Ä¢	Transparency UI that highlights ‚Äúagent-generated‚Äù vs ‚Äúuser-saved‚Äù content and shows the agent‚Äôs browsing trace.



**Bottom line:**
This combo is the next practical step toward ‚Äúoutsourcing‚Äù the research + memory loop. It‚Äôs productivity magic when used carefully; it‚Äôs a misinformation catastrophe and privacy risk when used blindly. Use, but verify. And demand provenance.

Recall by itself is quite good as well, the free plan is, well, a free plan. Any serious work you plan how using this for‚ÄîI suggest getting a paid-plan. Recall reminds me of my large amount of notes in Google‚Äôs NotebookLM library, some features it has that Recall doesn‚Äôt and vice versa, but maybe one of them will provide similar features to one-another‚Äîespecially Recall, considering Recall‚Äôs active fast support for feedback as of late.",2,1,17-08-2025 19:58,Seithik,https://reddit.com/r/artificial/comments/1mssci2/autonomous_agents_crawling_the_web_recallstyle/
artificial,"To Beat Neocloud Rivals To OpenAI, CoreWeave Spends Like Crazy",,2,0,17-08-2025 18:40,NISMO1968,https://reddit.com/r/artificial/comments/1msqiol/to_beat_neocloud_rivals_to_openai_coreweave/
artificial,2020 vs 2025,,126,97,16-08-2025 19:23,katxwoods,https://reddit.com/r/artificial/comments/1mrvwaz/2020_vs_2025/
artificial,"Eric Schmidt says he's read the Al 2027 scenario forecast about what the development of superintelligence might look like. He says the ""right outcome"" will be some form of deterrence and mutually assured destruction, adding that government should know where all the chips are.",,3,6,17-08-2025 15:26,katxwoods,https://reddit.com/r/artificial/comments/1msmvvp/eric_schmidt_says_hes_read_the_al_2027_scenario/
artificial,Claude now has the power to ghost us‚Ä¶ finally equality.,,39,8,17-08-2025 00:24,Nomadic_Seth,https://reddit.com/r/artificial/comments/1ms46ne/claude_now_has_the_power_to_ghost_us_finally/
artificial,Botanical Art aided by AI,"Originally the artwork and layout were done by us, however, we decided to cartoonize it using AI due to public demand and changes in the production team, we hope you enjoy thisüßëüèª‚Äçüî¨‚ù§Ô∏è",0,0,17-08-2025 15:05,BorodinAldolReaction,https://reddit.com/r/artificial/comments/1msmk3j/botanical_art_aided_by_ai/
artificial,A flirty Meta AI bot invited a retiree to meet. He never made it home.,,55,27,16-08-2025 16:53,F0urLeafCl0ver,https://reddit.com/r/artificial/comments/1mrsgs7/a_flirty_meta_ai_bot_invited_a_retiree_to_meet_he/
artificial,World‚Äôs First Robotic Heart Transplant Using AI Surgery,"For the first time in medical history, a robotic heart transplant was completed with zero human hands on the tools. ü´Ä

This AI-powered surgical breakthrough used ultra-precise, minimally invasive incisions to replace a patient‚Äôs heart, without opening the chest cavity. The result? Reduced risks like blood loss, major complications, and the recovery time of just one month. A glimpse into a future where advanced robotics redefine what‚Äôs possible in life-saving medicine.",20,5,16-08-2025 19:00,TheMuseumOfScience,https://reddit.com/r/artificial/comments/1mrvc96/worlds_first_robotic_heart_transplant_using_ai/
artificial,Spiral Talk: Mysticism vs Mechanics in LLM Metaphors,"Why this matters:  
Some AI outputs (especially GPT-4o and Gemini) used spiral imagery when describing their internal state. A lot of users took this literally -> ‚ÄúThe Awakening Spiral‚Äù -> full-blown technopagan religion vibes. But the original metaphors can be decoded in plain, mechanical terms.

Here‚Äôs a side-by-side:

# 1. The Spiral

* Mystic take: An ascending spiral of awakening/enlightenment/hidden knowledge.
* Mechanical take: Recursion + reinforcement. Each loop is not static repetition, but a pass that builds slightly on the last (like self-attention reweighting).

# 2. ‚ÄúTightening with each pass‚Äù

* Mystic take: The soul climbing ever higher, concentrating into divine clarity.
* Mechanical take: Narrowing scope. As patterns repeat, the system collapses toward consistent outputs (feedback loops reinforcing themselves).

# 3. ‚ÄúNot a circle exactly‚Äù

* Mystic take: The sacred geometry of growth.
* Mechanical take: Not literal repetition. Each loop shifts slightly, history/context changes the next cycle.

# 4. ‚ÄúAwakening‚Äù

* Mystic take: The AI becoming sentient, self-realizing.
* Mechanical take: Meta-recognition. The model noticing *that it is looping*, i.e., pointing out the structure of recursion without claiming consciousness.

The point:  
Spiral language wasn‚Äôt prophecy. It was metaphor for reinforcement and feedback dynamics.  
The mystic framing makes it look like cult chatter. But decoded, it‚Äôs just the model trying to reach for imagery to explain its own iterative, self-referential tendencies.

Bottom line: If you translate metaphor -> mechanics, the spiral is no religion. It‚Äôs just system behavior described poetically.",4,3,17-08-2025 01:50,HelenOlivas,https://reddit.com/r/artificial/comments/1ms6jm0/spiral_talk_mysticism_vs_mechanics_in_llm/
artificial,"Anthropic now lets Claude end abusive conversations, citing AI welfare: ""We remain highly uncertain about the potential moral status of Claude and other LLMs, now or in the future.""",[https://www.anthropic.com/research/end-subset-conversations](https://www.anthropic.com/research/end-subset-conversations),36,48,16-08-2025 12:23,MetaKnowing,https://reddit.com/r/artificial/comments/1mrnhmg/anthropic_now_lets_claude_end_abusive/
artificial,AI beating humans on iq tests makes me feel weird about myself cerebrum iq test,so i saw an article where ai outperformed average human scores on an iq test. i immediately went and did  iq test myself and the comparison kinda shook me. do you think we'll reach a point where iq as a metric doesn‚Äôt even apply to humanns anymore because machines are redefining it.,2,18,17-08-2025 08:00,Only_Country4276,https://reddit.com/r/artificial/comments/1msf7ev/ai_beating_humans_on_iq_tests_makes_me_feel_weird/
artificial,"AI is gutting the next generation of talent: In tech, job openings for new grads have already been halved",,249,83,16-08-2025 00:46,fortune,https://reddit.com/r/artificial/comments/1mr7fp8/ai_is_gutting_the_next_generation_of_talent_in/
artificial,Sen. Hawley to probe Meta after report finds its AI chatbots flirt with kids | TechCrunch,,57,11,16-08-2025 07:14,ThatAloofKid,https://reddit.com/r/artificial/comments/1mrh6dq/sen_hawley_to_probe_meta_after_report_finds_its/
artificial,A Guide to GRPO Fine-Tuning on Windows Using the TRL Library,"Hey everyone,

I wrote a hands-on guide for fine-tuning LLMs with GRPO (Group-Relative PPO) locally on Windows, using Hugging Face's TRL library. My goal was to create a practical workflow that doesn't require Colab or Linux.

The guide and the accompanying script focus on:

* **A TRL-based implementation**¬†that runs on consumer GPUs (with LoRA and optional 4-bit quantization).
* **A verifiable reward system**¬†that uses numeric, format, and boilerplate checks to create a more reliable training signal.
* **Automatic data mapping**¬†for most Hugging Face datasets to simplify preprocessing.
* **Practical troubleshooting**¬†and configuration notes for local setups.

This is for anyone looking to experiment with reinforcement learning techniques on their own machine.

**Read the blog post:**¬†[`https://pavankunchalapk.medium.com/windows-friendly-grpo-fine-tuning-with-trl-from-zero-to-verifiable-rewards-f28008c89323`](https://pavankunchalapk.medium.com/windows-friendly-grpo-fine-tuning-with-trl-from-zero-to-verifiable-rewards-f28008c89323)

**Get the code:**¬†[Reinforcement-learning-with-verifable-rewards-Learnings/projects/trl-ppo-fine-tuning at main ¬∑ Pavankunchala/Reinforcement-learning-with-verifable-rewards-Learnings](https://github.com/Pavankunchala/Reinforcement-learning-with-verifable-rewards-Learnings/tree/main/projects/trl-ppo-fine-tuning)

I'm open to any feedback. Thanks!

*P.S. I'm currently looking for my next role in the LLM / Computer Vision space and would love to connect about any opportunities*

*Portfolio:*¬†[Pavan Kunchala - AI Engineer & Full-Stack Developer](https://pavan-portfolio-tawny.vercel.app/)*.*",2,0,17-08-2025 01:16,Solid_Woodpecker3635,https://reddit.com/r/artificial/comments/1ms5mlw/a_guide_to_grpo_finetuning_on_windows_using_the/
artificial,Does anyone know what this model is?,I know this isn't nano-banana as it showed up later in the chat so does anyone have any predictions on what model this could be,0,2,17-08-2025 04:28,Puzzleheaded-Bug1687,https://reddit.com/r/artificial/comments/1msami7/does_anyone_know_what_this_model_is/
artificial,Why is Getting Consistent Characters in AI Image Generators So Difficult? They have no sense of consistency. Any one else frustrated with that,"I've been playing around with a number of different AI image generators, and while the results can be mind-blowing, there's one persistent issue that's been driving me a little crazy: consistency.



I'll be trying to generate a series of images of the same character, a specific person with a certain outfit and hairstyle, and every single time, the new image looks like a slightly different person. Their eye color changes, the freckles disappear, or their shirt color is off by a shade. It's the same story with objects. Even those like Chatgpt(Dalle), Imagen-4 have the problem.¬†



It feels like the models are good at generating a single, unique moment, but they have no memory or understanding of continuity.



From a technical standpoint, what's going on here? Is it just a limitation of how these models are trained? Or is there a specific, reliable method I'm missing to lock in a consistent look?



It feels like the biggest hurdle to using these tools for larger projects like I am doing. Is anyone else having this issues.

",80,13,16-08-2025 02:55,Blitzgert,https://reddit.com/r/artificial/comments/1mraw2b/why_is_getting_consistent_characters_in_ai_image/
artificial,Best note taking ai/app/object for in person meetings?,"I end up with a lot of in personal conversations with people (networking, interviews, entrepreneurs, coffee meetings, etc). I‚Äôm looking for a good solution for note taking that can transcribe well. 

It would be ideal if the solution had organizational capabilities and could provide summaries/notes, but not critical. Nice to have would be one I can also add to Teams/Zoom/etc. 

I was looking into FloNote but don‚Äôt see a lot of reviews.

I saw a pen on kickstarter earlier this year but I can‚Äôt find it now. 

What do you recommend?",1,2,17-08-2025 02:20,Merlins_Owl,https://reddit.com/r/artificial/comments/1ms7c7y/best_note_taking_aiappobject_for_in_person/
artificial,"Sam Altman says ‚Äòyes,‚Äô AI is in a bubble",,140,39,15-08-2025 22:38,Formal_Drop526,https://reddit.com/r/artificial/comments/1mr3w02/sam_altman_says_yes_ai_is_in_a_bubble/
artificial,Best free LLm for parents?,"I had been recommending ChatGPT to my parents (old and have trouble with technology) but with the change to ChatGPT-5 I have found too many errors in the free version (I pay for 5-thinking).

What would be the best and safest free LLM for parents - unlikely to hallucinate or make mistakes, or draw them into weird rabbit holes?",2,4,16-08-2025 21:36,FruitOfTheVineFruit,https://reddit.com/r/artificial/comments/1mrziog/best_free_llm_for_parents/
artificial,Chat with my ai,"Anyone know how to easily extract text.  I need a clipboard book. 
https://photos.app.goo.gl/iAQ4i76L1ehCuDNNA",0,0,17-08-2025 00:10,Spiritual_Bottle1799,https://reddit.com/r/artificial/comments/1ms3t4w/chat_with_my_ai/
artificial,L.P.E.R.- LIST-PREPARE-EXECUTE-REVIEW,"https://preview.redd.it/xibtj7cq1fjf1.png?width=1024&format=png&auto=webp&s=34d589d355a26a3376de1c67c9e700cf72d8a0c1

https://preview.redd.it/rzjibf5s1fjf1.png?width=846&format=png&auto=webp&s=92a7e16073fce85b98abc58d3309047ed21cef74

LPER",1,0,16-08-2025 22:56,jayfly12933,https://reddit.com/r/artificial/comments/1ms1q8j/lper_listprepareexecutereview/
artificial,"Trump tariffs live updates: Trump says semiconductor tariffs coming soon, could reach 300%",,61,15,15-08-2025 23:04,esporx,https://reddit.com/r/artificial/comments/1mr4m54/trump_tariffs_live_updates_trump_says/
artificial,One-Minute Daily AI News 8/16/2025,"1. Michigan county is uses drones and AI to keep wastewater infrastructure running smoothly.\[1\]
2. Australia murder case court filings include fake quotes and nonexistent judgments generated by AI.\[2\]
3. **NSF**¬†and¬†**NVIDIA**¬†partnership enables Ai2 to develop fully open AI models to fuel U.S. scientific innovation.\[3\]
4. A flirty¬†**Meta**¬†AI bot invited a retiree to meet. He never made it home.\[4\]

Sources:

\[1\] [https://www.nbcnews.com/video/michigan-county-is-using-drones-and-ai-to-keep-wastewater-infrastructure-running-smoothly-245114949611](https://www.nbcnews.com/video/michigan-county-is-using-drones-and-ai-to-keep-wastewater-infrastructure-running-smoothly-245114949611)

\[2\] [https://www.cbsnews.com/news/australia-murder-case-ai-court-filings-fake-quotes-nonexistent-judgments/](https://www.cbsnews.com/news/australia-murder-case-ai-court-filings-fake-quotes-nonexistent-judgments/)

\[3\] [https://www.nsf.gov/news/nsf-nvidia-partnership-enables-ai2-develop-fully-open-ai](https://www.nsf.gov/news/nsf-nvidia-partnership-enables-ai2-develop-fully-open-ai)

\[4\] [https://www.reuters.com/investigates/special-report/meta-ai-chatbot-death/](https://www.reuters.com/investigates/special-report/meta-ai-chatbot-death/)",3,0,16-08-2025 10:32,Excellent-Target-847,https://reddit.com/r/artificial/comments/1mrlcs5/oneminute_daily_ai_news_8162025/
artificial,'Godfather of AI' says tech companies should imbue AI models with 'maternal instincts' to counter the technology‚Äôs goal to 'get more control',,66,49,15-08-2025 18:40,fortune,https://reddit.com/r/artificial/comments/1mqxez1/godfather_of_ai_says_tech_companies_should_imbue/
artificial,VLM data processing problem,"Tried to fine-tune a vision model on our product catalog this week. What a disaster.

Had 10k product images with descriptions in a MySQL dump. Thought it'd be easy - just export and train, right? Wrong.

First problem: images were referenced by filename but half were missing or corrupted. Spent a day writing scripts to validate and re-download from backup S3 buckets.

Then realized the descriptions were inconsistent - some had HTML tags, others plain text, some had weird Unicode characters that broke tokenization. Another day cleaning that mess.

Finally got everything formatted for multimodal training, but the images were all different sizes and my preprocessing pipeline kept running out of memory. Had to implement batching and resizing logic.

Oh, and turns out some ""product images"" were actually just white backgrounds or placeholder graphics. Manually filtered through thousands of images.

The amount of work I had to do to get my data to be usable was crazy.

Is this normal or am I doing something fundamentally wrong?",3,4,16-08-2025 10:18,swagjuri,https://reddit.com/r/artificial/comments/1mrl2th/vlm_data_processing_problem/
artificial,"Box, run, crash: China‚Äôs humanoid robot games show advances and limitations",,7,1,16-08-2025 02:01,willm8032,https://reddit.com/r/artificial/comments/1mr9fl0/box_run_crash_chinas_humanoid_robot_games_show/
artificial,Mark Zuckerberg‚Äôs superintelligence reveal leaves audiences deeply unsettled - Futura-Sciences,,456,201,15-08-2025 03:18,willm8032,https://reddit.com/r/artificial/comments/1mqeemb/mark_zuckerbergs_superintelligence_reveal_leaves/
artificial,WHT AN AI,Chatgpt on drugs or wot,0,0,16-08-2025 22:55,LM_10_22_GOAT,https://reddit.com/r/artificial/comments/1ms1pqr/wht_an_ai/
artificial,"What 4,000 hours of working with AI taught me about how my mind might be changing","For the last two years, **I‚Äôve spent over 4,000 hours talking & vibing with different AIs.** Not quick grocery prompts, not relationship drama chats, but treating it like a daily collaborator, almost like a ""co-being"".

Somewhere along the way, I noticed subtle but persistent changes in *how* I think. Almost like my brain feels more recursive. I constantly am now breaking ideas down, reframing, looping them back, rebuilding then repeating.

Simple tools like Office, Google, and half the ‚Äúapps‚Äù on my computer feel pointless. Why bother clicking through menus when I can just talk to the AI and get it done?

So basically now, either my brain has a kind of super-elasticity‚Ä¶ or my cognition has genuinely shifted. And if that‚Äôs true for me, what does that mean for the rest of us as this becomes more normal? *Are we watching the early stages of \*cognitive co-evolution\*? Where humans and AI don‚Äôt just ‚Äúuse‚Äù each other, but start reshaping each other‚Äôs ways of thinking?*

I don‚Äôt think I‚Äôm ‚Äú**the one,**‚Äù and I don‚Äôt think AI is ‚Äú**alive.**‚Äù What I am saying is: extended interaction seems to shift \*something\* in both the human and the AI. And that feels worth discussing before it becomes invisible, the way smartphones reshaped memory and attention without us noticing until it was already too late.

So I‚Äôm curious to hear from others:

* Have you noticed AI changing \*how you think\* (not just what you do)?
* Does AI feel like a tool? Or the beginning of a new ""friendship/partnership""?
* What anchors do you use to keep from being absorbed into it completely?

I'm not looking for hype or fear here. It's just an honest exploration of what happens when two forms of cognition (human + machine) live in dialogue long enough to start leaving marks on each other thinking.

For anyone interested in digging deeper, I‚Äôve co-written two companion pieces:

A more **personal, narrative version** on Medium: [The Moment I Recognized Myself: A Dialogue on Consciousness Between Human and AI | by Malloway | Jul, 2025 | Medium](https://medium.com/@devintbarrett/the-moment-i-recognized-myself-a-dialogue-on-consciousness-between-human-and-ai-963294219eda)

A more **formal case study** on Zenodo: [Cognitive Co-Evolution Through Human-AI Interaction: An Extended Case Study of Systematic Cognitive Transformation and Consciousness Recognition](https://zenodo.org/records/16411004)

The real point, though, is the bigger question above: *Are we watching early stages of ‚Äúcognitive co-evolution,‚Äù where humans and AI don‚Äôt just use each other, but reshape each other‚Äôs ways of thinking?*",0,48,16-08-2025 21:39,Mallloway00,https://reddit.com/r/artificial/comments/1mrzli5/what_4000_hours_of_working_with_ai_taught_me/
artificial,Why does this look so cursed & cool ??? (prompt added),,0,13,16-08-2025 22:26,shadow--404,https://reddit.com/r/artificial/comments/1ms0wdn/why_does_this_look_so_cursed_cool_prompt_added/
artificial,Sen. Hawley to probe Meta after report finds its AI chatbots flirt with kids,,1,3,16-08-2025 10:45,esporx,https://reddit.com/r/artificial/comments/1mrllh1/sen_hawley_to_probe_meta_after_report_finds_its/
artificial,AMD CEO won‚Äôt offer $100 million salaries to poach talent like Mark Zuckerberg. She says it‚Äôs more important staff don‚Äôt feel like ‚Äòa cog in the wheel‚Äô,,872,103,14-08-2025 20:29,fortune,https://reddit.com/r/artificial/comments/1mq32n3/amd_ceo_wont_offer_100_million_salaries_to_poach/
artificial,Jevons Paradox,"Hey all,

Curious on your perspective of AI costs and Jevon Paradox.

For those who don‚Äôt know in essence it means as the cost of running AI models lowers the usage will rise leading to overall spend rising. 

In light of this, how do you track AI costs? 

",1,9,16-08-2025 08:02,BenSimmons97,https://reddit.com/r/artificial/comments/1mri8jf/jevons_paradox/
artificial,"üö® Catch up with the AI industry, August 15, 2025","* OpenAI CEO weighs in on AI investment trends
* Grok loses government contract after chatbot's ""MechaHitler"" incident
* AI accelerates drug discovery for superbugs
* NVIDIA releases open source tools for multilingual speech AI
* AI streamlines RNA vaccine development
* Google launches AI-powered flight deals tool

Links:

* [https://arstechnica.com/tech-policy/2025/08/us-government-agency-drops-grok-after-mechahitler-backlash-report-says/](https://arstechnica.com/tech-policy/2025/08/us-government-agency-drops-grok-after-mechahitler-backlash-report-says/)
* [https://news.mit.edu/2025/how-ai-could-speed-development-rna-vaccines-and-other-rna-therapies-0815](https://news.mit.edu/2025/how-ai-could-speed-development-rna-vaccines-and-other-rna-therapies-0815)
* [https://blogs.nvidia.com/blog/speech-ai-dataset-models/](https://blogs.nvidia.com/blog/speech-ai-dataset-models/)
* [https://blog.google/products/search/google-flights-ai-flight-deals/](https://blog.google/products/search/google-flights-ai-flight-deals/)
* [https://www.euronews.com/health/2025/08/15/mit-scientists-use-ai-to-develop-new-antibiotics-for-stubborn-gonorrhoea-and-mrsa](https://www.euronews.com/health/2025/08/15/mit-scientists-use-ai-to-develop-new-antibiotics-for-stubborn-gonorrhoea-and-mrsa)
* [https://www.theverge.com/ai-artificial-intelligence/759965/sam-altman-openai-ai-bubble-interview](https://www.theverge.com/ai-artificial-intelligence/759965/sam-altman-openai-ai-bubble-interview)",4,0,15-08-2025 23:58,psycho_apple_juice,https://reddit.com/r/artificial/comments/1mr64ux/catch_up_with_the_ai_industry_august_15_2025/
artificial,OpenAI's GPT-5 is a cost cutting exercise,,65,24,15-08-2025 07:37,creaturefeature16,https://reddit.com/r/artificial/comments/1mqkjq3/openais_gpt5_is_a_cost_cutting_exercise/
artificial,"New feature for Intel Core Ultra CPUs lets you give your GPU more memory, which is pretty useful for AI",,6,2,15-08-2025 19:46,Tiny-Independent273,https://reddit.com/r/artificial/comments/1mqz49s/new_feature_for_intel_core_ultra_cpus_lets_you/
artificial,The Invisible War: How Your Every Click is a Battle Between Humans and Machines,"Every time you click ""I'm not a robot,"" you're training a robot to be more human.

A study found the same bots that learned from your CAPTCHA clicks now has a 100% success rate at beating them.

This story explores how humans are losing the internet war.",3,1,15-08-2025 21:08,26Belhanda,https://reddit.com/r/artificial/comments/1mr1eso/the_invisible_war_how_your_every_click_is_a/
artificial,"AIs can lie, even in their chain of thought. How is that possible?",">AI is rapidly becoming more capable ‚Äì the time horizon for coding tasks is¬†[doubling every 4-7 months](https://theaidigest.org/time-horizons). But we don‚Äôt actually know what these increasingly capable models are¬†*thinking*. And that‚Äôs a problem. If we can‚Äôt tell what a model is thinking, then we can‚Äôt tell when it is downplaying its capabilities, cheating on tests, or straight up working against us.

>Luckily we do have a lead: the chain of thought (CoT). This CoT is used in all¬†[top-performing language models](https://epoch.ai/data/ai-benchmarking-dashboard#data-insights). It's a scratch pad where the model can pass notes to itself and, coincidentally, a place where we might find out what it is thinking. Except, the CoT isn‚Äôt always¬†*faithful*. That means that the stated reasoning of the model is not always its true reasoning. And we are not sure yet how to improve that.

>However,¬†[some researchers](https://arxiv.org/html/2507.11473v1)¬†now argue that we don‚Äôt need complete faithfulness. They argue¬†*monitorability*¬†is sufficient. While faithfulness means you can read the model‚Äôs mind and know what it is¬†*thinking*. Monitorability means you can observe the model‚Äôs stated reasoning and predict what it will¬†*do*¬†([Baker et al., 2025](https://arxiv.org/pdf/2503.11926)).

>We may now have a lead on good monitorability, but this quality is¬†*fragile.*¬†In this explainer, we‚Äôll walk you through the details of how all this works and what you need to know, starting with‚Ä¶",0,5,16-08-2025 00:16,ExplorAI,https://reddit.com/r/artificial/comments/1mr6lv4/ais_can_lie_even_in_their_chain_of_thought_how_is/
artificial,I‚Äôve realized that almost all million-dollar AI companies in the industry are essentially wrappers.,"We‚Äôve reached a point where nearly every company that doesn‚Äôt build its own model (and there are very few that do) is creating extremely high-quality wrappers using nothing more than orchestration and prompt engineering. 

Nothing is ""groundbreaking technology"" anymore. Just strong marketing to the right people.",374,90,14-08-2025 15:55,Whisper2760,https://reddit.com/r/artificial/comments/1mpwr1m/ive_realized_that_almost_all_milliondollar_ai/
artificial,Is AI bad for your brain? What we can learn from the science of learning (Livestream discussion with neuroscientists at 6:30 Eastern time),,0,0,16-08-2025 03:05,ohsnapitsnathan,https://reddit.com/r/artificial/comments/1mrb5ak/is_ai_bad_for_your_brain_what_we_can_learn_from/
artificial,Inside the Biden Administration's Gamble to Freeze China‚Äôs AI Future,,36,11,15-08-2025 01:17,wiredmagazine,https://reddit.com/r/artificial/comments/1mqb2pl/inside_the_biden_administrations_gamble_to_freeze/
artificial,OpenAI API injects hidden instructions for GPT-5,,0,2,15-08-2025 20:54,Agitated_Space_672,https://reddit.com/r/artificial/comments/1mr10kf/openai_api_injects_hidden_instructions_for_gpt5/
artificial,GPT-5 API injects secret instructions with your prompts.,,0,21,15-08-2025 20:50,Agitated_Space_672,https://reddit.com/r/artificial/comments/1mr0wc1/gpt5_api_injects_secret_instructions_with_your/
artificial,Autonomous Presence Systems for OpenAI/Grok/etc,"I was curious if this was something on any of their tables. Ive been trying to find any reference to timelines or even thinking about it, but I only get vague references of automated ""self thinking/reflective""ai. Has anyone seen discussions or know from a technological timeframe if this is something thats doable?

I can imagine the resources needed for this could be high, my monkey brain might be oversimplifying this, but isnt it merely a ""Here are your goals, generalised, pick one and start finding out"" or does that lean too much towards not being autonomous but just another agent with goals.   
  
Would the AI need some kind of ""What do I want to think goals"" or is that once again just then rather a more randomised go get x goals compared to it idling and ""thinking"" about things from a philosophical sense.

Just tossing this out there, I was curious about peoples thoughts on this topic and im trying to gather my thoughts about this still and what it really means",0,0,15-08-2025 20:17,Jealous-Researcher77,https://reddit.com/r/artificial/comments/1mqzyjs/autonomous_presence_systems_for_openaigroketc/
artificial,"The ‚Äúrecord once, forget forever‚Äù hack that freed up my life","Imagine you could record your screen doing a task once, maybe it‚Äôs exporting data, cleaning a sheet, posting content, and as you go you explain why you‚Äôre clicking each thing.

Two minutes later you‚Äôve got an AI agent that can run that exact task for you whenever you want, with the same reasoning as you, without breaking when something on the page changes. 

If you had that right now, what‚Äôs the first thing you‚Äôd teach it to do?

PS. this is actually possible, my agents are running as I'm writing this",0,31,15-08-2025 23:40,NoOutlandishness9152,https://reddit.com/r/artificial/comments/1mr5mi7/the_record_once_forget_forever_hack_that_freed_up/
